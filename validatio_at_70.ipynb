{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_xHqE173acg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldY0TDpP4Bw_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b43c78e"
      },
      "source": [
        "1. Environment Setup — Colab Mount, Paths, Assertions, Self-Test\n",
        "2. Imports, Reproducibility, Device Selection, Self-Check\n",
        "3. Training Shards — Discovery, Local Staging, Concatenation, Normalization Wrapper\n",
        "4. FER2013 CSV Splits — Validation/Test Datasets with Consistent Preprocessing\n",
        "5. DataLoaders and Optional Visualization Hook\n",
        "6. Metrics — Accuracy, Class Weights, and Composite Losses (Label Smoothing + Focal)\n",
        "7. MixUp and CutMix Utilities (+ Mixed-Criterion Wrapper)\n",
        "8. EMA (Weights) — Backup/Restore and Safety Checks\n",
        "9. Base Training/Evaluation Mixin (training_step/validation_step/aggregation)\n",
        "10. Training Hyperparameters and Global Knobs\n",
        "11. Model Definition — EfficientNet-B0 + CBAM + optional Sobel\n",
        "12. Optimizer & Scheduler (Warmup-Cosine) & EarlyStopping\n",
        "13. Training Loop — AMP, EMA, MixUp/CutMix, Save-Best Checkpoint\n",
        "14. Launch Training — Build Optimizer/Scheduler/EMA and Fit\n",
        "15. Evaluation Utilities — Base / EMA / EMA + TTA\n",
        "16. Run Evaluation — Validation and Test (Base, EMA, EMA+TTA)\n",
        "17. FLOPs Measurement (fvcore) for 96×96\n",
        "18. Efficiency Summary — Map Metrics, Select Best, Compute Accuracy/GFLOPs\n",
        "19. Save Final Checkpoint — Best Weights + Timestamped Copy\n",
        "20. Reload Checkpoint for Inference — Sanity Forward Pass\n",
        "21. FLOPs Calculation (fvcore) — Standalone Report Cell\n",
        "22. Efficiency Report Preparation — Name Mapping & Best Selection\n",
        "23. Efficiency Function — Accuracy(%) per GFLOP Utility\n",
        "24. Run Efficiency Report — Compute and Print Efficiency Score\n",
        "25. Save Final Checkpoint — Stage C/Final Model Artifact\n",
        "26. Wrap-Up — Final Metrics Summary and Completion Banner\n",
        "27. Stage A (AffectNet) — RGB, ImageNet Normalization, Training\n",
        "28. Stage A Save — Write AffectNet Checkpoint\n",
        "29. Stage B (RAF-DB) — Load Stage A, Fine-Tune on RAF-DB\n",
        "30. Stage B Save — Write RAF-DB Checkpoint\n",
        "31. Stage C (FER2013) — Load Stage B, Final Fine-Tune on FER2013\n",
        "32. Stage C Save — Write FER2013 Checkpoint (Multi-Stage Complete)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OMZPNU-4fwT"
      },
      "source": [
        "Stage 0 — Boot & Storage Safety\n",
        "\n",
        "Cell 01 — Folder & Storage Debug (Auto-Create + Quota Warning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lod2dmJ5CAOk",
        "outputId": "5cb9b08d-567d-451f-cb9a-12b464c3e590"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stage0] Disk @ /content/project — total=112.64 GB, used=38.79 GB, free=73.84 GB\n"
          ]
        }
      ],
      "source": [
        "# Creates core directories locally and prints disk quota.\n",
        "\n",
        "import os, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_NAME  = \"facial_expression_recognition_2025\"\n",
        "PROJECT_ROOT  = Path(\"./project\")\n",
        "DATA_ROOT     = Path(\"./data\")\n",
        "CKPT_DIR      = PROJECT_ROOT / \"checkpoints\"\n",
        "LOG_DIR       = PROJECT_ROOT / \"logs\"\n",
        "MIN_FREE_GB   = 2.0  # warn if below this free space\n",
        "\n",
        "for p in [PROJECT_ROOT, DATA_ROOT, CKPT_DIR, LOG_DIR]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "usage = shutil.disk_usage(str(PROJECT_ROOT))\n",
        "free_gb = usage.free / (1024**3)\n",
        "print(f\"[Stage0] Disk @ {PROJECT_ROOT.resolve()} — total={usage.total/(1024**3):.2f} GB, \"\n",
        "      f\"used={usage.used/(1024**3):.2f} GB, free={free_gb:.2f} GB\")\n",
        "if free_gb < MIN_FREE_GB:\n",
        "    print(f\"[Stage0][WARN] Low free space (< {MIN_FREE_GB:.1f} GB). Consider cleaning Drive.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md70Tsg_M0Uj"
      },
      "source": [
        "#Cell 02 — Environment Setup (Colab Mount, Paths, Assertions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-CPW6ggM3uc",
        "outputId": "8e819de9-17d5-47ca-aef7-84e55b75c7c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "[Stage0] Drive unmounted.\n",
            "Mounted at /content/drive\n",
            "[Stage0] Google Drive mounted.\n",
            "[Stage0] FER CSV: /content/drive/MyDrive/fer2013.csv\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "def in_colab() -> bool:\n",
        "    return \"google.colab\" in sys.modules\n",
        "\n",
        "if in_colab():\n",
        "    from google.colab import drive\n",
        "\n",
        "    # First unmount if already mounted\n",
        "    try:\n",
        "        drive.flush_and_unmount()\n",
        "        print(\"[Stage0] Drive unmounted.\")\n",
        "    except Exception as e:\n",
        "        print(f\"[Stage0] No previous mount or already unmounted. ({e})\")\n",
        "\n",
        "    # Now remount\n",
        "    drive.mount(\"/content/drive\", force_remount=True)\n",
        "    print(\"[Stage0] Google Drive mounted.\")\n",
        "\n",
        "# Path to FER2013\n",
        "FER_CSV_PATH = Path(\"/content/drive/MyDrive/fer2013.csv\")\n",
        "print(f\"[Stage0] FER CSV: {FER_CSV_PATH if FER_CSV_PATH.exists() else 'NOT FOUND'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmnEFvxuM-OZ"
      },
      "source": [
        "#Cell 03 — Global Switches & Run Config (Single Source of Truth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXqcOpdrNBci",
        "outputId": "85c5f6c6-f241-42c8-f786-1493d93a52d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stage0] CONFIG snapshot:\n",
            "  - AUG_ALPHA       : 0.65\n",
            "  - AUG_CAP_LATE    : True\n",
            "  - BATCH_SIZE      : 192\n",
            "  - CKPT_DIR        : project/checkpoints\n",
            "  - DATA_ROOT       : data\n",
            "  - DRY_RUN         : False\n",
            "  - FER_CSV_PATH    : /content/drive/MyDrive/fer2013.csv\n",
            "  - IMG_SIZE        : 96\n",
            "  - LOG_DIR         : project/logs\n",
            "  - NUM_WORKERS     : 6\n",
            "  - PROJECT_ROOT    : project\n",
            "  - RUN_ALL         : False\n",
            "  - RUN_FER         : True\n",
            "  - RUN_STAGE_A     : False\n",
            "  - RUN_STAGE_B     : False\n",
            "  - RUN_STAGE_C     : False\n",
            "  - SAVE_BEST_PATH  : project/checkpoints/best_fer.pth\n",
            "  - SEED            : 42\n",
            "  - TAPER_MIX_LATE  : True\n",
            "  - USE_AUG         : True\n",
            "  - USE_AUG_ADV     : True\n",
            "  - USE_CUTMIX      : True\n",
            "  - USE_EMA         : True\n",
            "  - USE_MIXUP       : True\n",
            "  - USE_TTA         : False\n"
          ]
        }
      ],
      "source": [
        "# --- CONFIG (single source of truth) — UPDATED ---\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure FER CSV path points to your Drive root\n",
        "FER_CSV_PATH = Path(\"/content/drive/MyDrive/fer2013.csv\")\n",
        "\n",
        "CONFIG = {\n",
        "    # === Feature toggles ===\n",
        "    \"USE_AUG\": True,          # enable training-time augmentation\n",
        "    \"USE_AUG_ADV\": True,      # advanced FER policy (AugMixLite + occlusion/elastic etc.)\n",
        "    \"AUG_ALPHA\": 0.65,        # blend coefficient for AugMixLite\n",
        "    \"USE_MIXUP\": True,\n",
        "    \"USE_CUTMIX\": True,\n",
        "    \"USE_EMA\": True,\n",
        "    \"USE_TTA\": False,         # keep Val clean; enable TTA only for Test in Cell 27\n",
        "\n",
        "    # === Late-phase controls ===\n",
        "    \"AUG_CAP_LATE\": True,     # cap augmentation strength in the last ~30% epochs\n",
        "    \"TAPER_MIX_LATE\": True,   # taper MixUp/CutMix late\n",
        "\n",
        "    # === Run routing ===\n",
        "    \"RUN_FER\": True,\n",
        "    \"RUN_STAGE_A\": False,\n",
        "    \"RUN_STAGE_B\": False,\n",
        "    \"RUN_STAGE_C\": False,\n",
        "    \"RUN_ALL\": False,\n",
        "    \"DRY_RUN\": False,\n",
        "\n",
        "    # === Dataloading & reproducibility (throughput tuned for Colab 83GB/40GB) ===\n",
        "    \"SEED\": 42,\n",
        "    \"NUM_WORKERS\": 6,         # try 6; if GPU still starves, try 8. If RAM spikes, drop to 4.\n",
        "    \"BATCH_SIZE\": 192,        # safe at 96x96 with 40GB GPU; if OOM, use 176/160/128\n",
        "    \"IMG_SIZE\": 96,\n",
        "\n",
        "    # === Paths ===\n",
        "    \"PROJECT_ROOT\": PROJECT_ROOT,\n",
        "    \"DATA_ROOT\": DATA_ROOT,\n",
        "    \"CKPT_DIR\": CKPT_DIR,\n",
        "    \"LOG_DIR\": LOG_DIR,\n",
        "    \"SAVE_BEST_PATH\": CKPT_DIR / \"best_fer.pth\",\n",
        "    \"FER_CSV_PATH\": FER_CSV_PATH,\n",
        "}\n",
        "\n",
        "# Nice, aligned snapshot\n",
        "print(\"[Stage0] CONFIG snapshot:\")\n",
        "for k in sorted(CONFIG.keys()):\n",
        "    print(f\"  - {k:16s}: {CONFIG[k]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfXgWu_NNDYj"
      },
      "source": [
        "#Cell 04 — Imports, Versions, Reproducibility, Device Self-Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JwHVOA2NGPf",
        "outputId": "f9de2789-2d54-4cfc-ae7f-384a979b1c6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stage0] torch=2.8.0+cu126, torchvision=0.23.0+cu126, numpy=2.0.2\n",
            "[Stage0] CUDA:0 — NVIDIA A100-SXM4-40GB — 39.6 GB VRAM\n"
          ]
        }
      ],
      "source": [
        "import math, random, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as VF\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "print(f\"[Stage0] torch={torch.__version__}, torchvision={torchvision.__version__}, numpy={np.__version__}\")\n",
        "\n",
        "SEED = int(CONFIG[\"SEED\"])\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    dev_id = torch.cuda.current_device()\n",
        "    props = torch.cuda.get_device_properties(dev_id)\n",
        "    print(f\"[Stage0] CUDA:{dev_id} — {props.name} — {props.total_memory/(1024**3):.1f} GB VRAM\")\n",
        "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
        "    print(\"[Stage0] Device: Apple MPS\")\n",
        "else:\n",
        "    print(\"[Stage0] Device: CPU\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KDrvY2HNaqo"
      },
      "source": [
        "#Cell 05 — Training Shards: Discovery & Local Staging (No Normalize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPN-6d-CNddO",
        "outputId": "f5f8c3f9-b9c1-44f8-bc59-64fa2f5b1db5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stage0] No shards directory present (this is fine).\n"
          ]
        }
      ],
      "source": [
        "# Optional shard discovery; safe no-op if you do not pre-generate shards.\n",
        "\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "SHARDS_ROOT = CONFIG[\"DATA_ROOT\"] / \"augmented_data\"\n",
        "LOCAL_STAGE = CONFIG[\"DATA_ROOT\"] / \"_local_stage\"\n",
        "LOCAL_STAGE.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if SHARDS_ROOT.exists():\n",
        "    shards = sorted([p for p in SHARDS_ROOT.rglob(\"*.pt\")])\n",
        "    print(f\"[Stage0] Found {len(shards)} shards under {SHARDS_ROOT}\")\n",
        "    if len(shards) > 0:\n",
        "        sample_dst = LOCAL_STAGE / shards[0].name\n",
        "        if not sample_dst.exists():\n",
        "            try:\n",
        "                shutil.copy2(shards[0], sample_dst)\n",
        "                print(f\"[Stage0] Staged sample shard → {sample_dst}\")\n",
        "            except Exception as e:\n",
        "                print(f\"[Stage0][WARN] Could not stage shard: {e}\")\n",
        "else:\n",
        "    print(\"[Stage0] No shards directory present (this is fine).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDnnfo0SNfpD"
      },
      "source": [
        "#Cell 06 — FER2013 CSV Parse & Split (Robust)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp2aJVzFNhaB",
        "outputId": "20cf8d87-3a14-4aed-b5f2-3c864b01847c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stage0] FER splits — train=28709, val=3589, test=3589\n"
          ]
        }
      ],
      "source": [
        "# Loads FER2013 from the fixed path and makes train/val/test DataFrames.\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "assert CONFIG[\"RUN_FER\"], \"RUN_FER=False; skip if not using FER2013.\"\n",
        "assert CONFIG[\"FER_CSV_PATH\"] is not None and Path(CONFIG[\"FER_CSV_PATH\"]).exists(), \\\n",
        "    \"FER2013 CSV not found at /content/drive/MyDrive/fer2013.csv\"\n",
        "\n",
        "fer_df = pd.read_csv(CONFIG[\"FER_CSV_PATH\"])\n",
        "expected_cols = {\"emotion\", \"pixels\"}\n",
        "assert expected_cols.issubset({c.lower() for c in fer_df.columns}), \\\n",
        "    f\"FER CSV missing required columns {expected_cols}. Found: {fer_df.columns.tolist()}\"\n",
        "\n",
        "if \"Usage\" in fer_df.columns:\n",
        "    tr_df = fer_df[fer_df[\"Usage\"] == \"Training\"].reset_index(drop=True)\n",
        "    va_df = fer_df[fer_df[\"Usage\"] == \"PublicTest\"].reset_index(drop=True)\n",
        "    te_df = fer_df[fer_df[\"Usage\"] == \"PrivateTest\"].reset_index(drop=True)\n",
        "else:\n",
        "    perm = np.random.permutation(len(fer_df))\n",
        "    n = len(fer_df); n_tr = int(0.8*n); n_va = int(0.1*n)\n",
        "    idx_tr, idx_va = perm[:n_tr], perm[n_tr:n_tr+n_va]\n",
        "    mask = np.zeros(n, dtype=bool); mask[idx_tr]=True; mask[idx_va]=True\n",
        "    tr_df = fer_df.iloc[idx_tr].reset_index(drop=True)\n",
        "    va_df = fer_df.iloc[idx_va].reset_index(drop=True)\n",
        "    te_df = fer_df.loc[~mask].reset_index(drop=True)\n",
        "\n",
        "print(f\"[Stage0] FER splits — train={len(tr_df)}, val={len(va_df)}, test={len(te_df)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpSeNJeZNjCn"
      },
      "source": [
        "#Cell 07 — Dataset Definition (48×48 → 96×96, No Normalize Yet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhid26vXNmQK",
        "outputId": "fb305989-989b-4d7c-b300-2da9bd410e04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stage0] Dataset objects built.\n"
          ]
        }
      ],
      "source": [
        "# CSV-backed dataset converting space-separated pixels → [1,H,W] float tensor.\n",
        "# Resize to 96×96 here; normalization is applied later (in aug or eval transform).\n",
        "\n",
        "class FER2013Dataset(Dataset):\n",
        "    def __init__(self, df, img_size=96):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_size = int(img_size)\n",
        "        if len(self.df) > 0:\n",
        "            _ = self._row_to_tensor(0)\n",
        "\n",
        "    def _row_to_tensor(self, idx: int) -> torch.Tensor:\n",
        "        px = self.df.iloc[idx][\"pixels\"]\n",
        "        arr = np.fromstring(str(px), sep=\" \", dtype=np.float32)\n",
        "        assert arr.size == 48*48, f\"Row {idx}: expected 2304 pixels, got {arr.size}\"\n",
        "        img = torch.from_numpy(arr.reshape(48, 48)).unsqueeze(0)  # [1,48,48]\n",
        "        img = VF.resize(img, [self.img_size, self.img_size],\n",
        "                        interpolation=torchvision.transforms.InterpolationMode.BILINEAR,\n",
        "                        antialias=True)\n",
        "        return img  # still [0..255]\n",
        "\n",
        "    def __len__(self): return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self._row_to_tensor(idx)\n",
        "        y = int(self.df.iloc[idx][\"emotion\"])\n",
        "        return x, y\n",
        "\n",
        "IMG_SIZE = int(CONFIG[\"IMG_SIZE\"])\n",
        "train_ds = FER2013Dataset(tr_df, img_size=IMG_SIZE)\n",
        "valid_ds = FER2013Dataset(va_df, img_size=IMG_SIZE)\n",
        "test_ds  = FER2013Dataset(te_df, img_size=IMG_SIZE)\n",
        "print(\"[Stage0] Dataset objects built.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXSE5ctVNn0G"
      },
      "source": [
        "#Cell 08 — DataLoaders (No Aug Yet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka5VEPz2Nr0-",
        "outputId": "feaec2a5-57dd-4e12-809e-5855fd61cb7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stage0] Train batch shape: torch.Size([192, 1, 96, 96]), torch.Size([192])\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE  = int(CONFIG[\"BATCH_SIZE\"])\n",
        "NUM_WORKERS = int(CONFIG[\"NUM_WORKERS\"])\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                      num_workers=NUM_WORKERS, pin_memory=True,\n",
        "                      persistent_workers=(NUM_WORKERS>0))\n",
        "valid_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE*2, shuffle=False,\n",
        "                      num_workers=NUM_WORKERS, pin_memory=True,\n",
        "                      persistent_workers=(NUM_WORKERS>0))\n",
        "test_dl  = DataLoader(test_ds,  batch_size=BATCH_SIZE*2, shuffle=False,\n",
        "                      num_workers=NUM_WORKERS, pin_memory=True,\n",
        "                      persistent_workers=(NUM_WORKERS>0))\n",
        "\n",
        "xb, yb = next(iter(train_dl))\n",
        "print(f\"[Stage0] Train batch shape: {xb.shape}, {yb.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzRNS4RMOiay"
      },
      "source": [
        "#Cell 09 — Optional Visualization Hook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HU_AbnxTOkKG"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid\n",
        "\n",
        "def show_batch(dl, nrow=16, title='Raw FER2013 batch (resized)'):\n",
        "    imgs, labels = next(iter(dl))\n",
        "    grid = make_grid(imgs[:nrow], nrow=nrow)\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.axis('off'); plt.title(title)\n",
        "    plt.imshow(grid.permute(1,2,0).squeeze(), cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "# Uncomment to preview\n",
        "#show_batch(train_dl)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRvueO8vOvFy"
      },
      "source": [
        "#Cell 10 — Augmentation Primitives (Grayscale-Friendly)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nTNv_xLoOxIF"
      },
      "outputs": [],
      "source": [
        "# ===== Advanced grayscale operators (tensor I/O) =====\n",
        "# INPUT  : x in [C=1,H,W], values in [0,255]\n",
        "# OUTPUT : same shape/range unless otherwise noted\n",
        "\n",
        "import math, random\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as VF\n",
        "from PIL import Image, ImageFilter, ImageOps\n",
        "import io\n",
        "\n",
        "# ---- Small utilities ----\n",
        "def _to_pil_gray(x255: torch.Tensor) -> Image.Image:\n",
        "    # [1,H,W] -> PIL 'L'\n",
        "    x = x255.clamp(0, 255).to(torch.uint8).squeeze(0).cpu().numpy()\n",
        "    return Image.fromarray(x, mode='L')\n",
        "\n",
        "def _from_pil_gray(img: Image.Image) -> torch.Tensor:\n",
        "    # PIL 'L' -> [1,H,W] float32 in [0,255]\n",
        "    return torch.tensor(np.array(img, dtype=np.uint8), dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "def _clamp255(x): return x.clamp(0.0, 255.0)\n",
        "\n",
        "# ---- Photometric / intensity ----\n",
        "def gauss_noise(x, sigma=0.02):\n",
        "    n = torch.randn_like(x) * (sigma * 255.0)\n",
        "    return _clamp255(x + n)\n",
        "\n",
        "def rand_gamma(x, gmin=0.8, gmax=1.25):\n",
        "    g = random.uniform(gmin, gmax)\n",
        "    x01 = (x / 255.0).clamp(0,1)\n",
        "    return (x01.pow(g) * 255.0)\n",
        "\n",
        "def rand_contrast(x, scale=0.25):\n",
        "    c = 1.0 + random.uniform(-scale, scale)\n",
        "    mean = x.mean(dim=(1,2), keepdim=True)\n",
        "    return _clamp255((x - mean) * c + mean)\n",
        "\n",
        "def rand_equalize(x):\n",
        "    img = _to_pil_gray(x); img = ImageOps.equalize(img)\n",
        "    return _from_pil_gray(img).to(x.dtype).to(x.device)\n",
        "\n",
        "def rand_jpeg(x, qmin=45, qmax=85):\n",
        "    img = _to_pil_gray(x)\n",
        "    buf = io.BytesIO()\n",
        "    img.save(buf, format='JPEG', quality=random.randint(qmin, qmax))\n",
        "    buf.seek(0)\n",
        "    img2 = Image.open(buf).convert('L')\n",
        "    return _from_pil_gray(img2).to(x.dtype).to(x.device)\n",
        "\n",
        "def rand_vignette(x, strength=0.25):\n",
        "    _, H, W = x.shape\n",
        "    yy, xx = torch.meshgrid(torch.linspace(-1,1,H,device=x.device),\n",
        "                            torch.linspace(-1,1,W,device=x.device), indexing='ij')\n",
        "    r = torch.sqrt(xx**2 + yy**2)\n",
        "    mask = 1.0 - strength * (r / r.max()).clamp(0,1)\n",
        "    return _clamp255(x * mask.unsqueeze(0))\n",
        "\n",
        "def rand_blur(x, k=3):\n",
        "    return VF.gaussian_blur(x, kernel_size=k)\n",
        "\n",
        "# ---- Geometric ----\n",
        "def rand_affine_small(x, max_rot=12.0, max_trans=0.08, max_shear=8.0, max_scale=0.08):\n",
        "    H, W = x.shape[-2:]\n",
        "    angle = random.uniform(-max_rot, max_rot)\n",
        "    trans = [int(random.uniform(-max_trans, max_trans) * W),\n",
        "             int(random.uniform(-max_trans, max_trans) * H)]\n",
        "    scale = 1.0 + random.uniform(-max_scale, max_scale)\n",
        "    shear = [random.uniform(-max_shear, max_shear), 0.0]\n",
        "    return VF.affine(x, angle=angle, translate=trans, scale=scale, shear=shear)\n",
        "\n",
        "def rand_pad_crop(x, pad=3):\n",
        "    # pad then random crop back to original size\n",
        "    _, H, W = x.shape\n",
        "    xpad = F.pad(x, (pad, pad, pad, pad), mode='reflect')\n",
        "    i = random.randint(0, 2*pad); j = random.randint(0, 2*pad)\n",
        "    return xpad[:, i:i+H, j:j+W]\n",
        "\n",
        "def rand_hflip(x, p=0.5):\n",
        "    return VF.hflip(x) if random.random() < p else x\n",
        "\n",
        "# Elastic deformation: small, smoothed displacement field\n",
        "def rand_elastic(x, alpha=1.0, sigma=4.0):\n",
        "    _, H, W = x.shape\n",
        "    # displacement fields\n",
        "    dx = torch.randn(1,1,H,W, device=x.device)\n",
        "    dy = torch.randn(1,1,H,W, device=x.device)\n",
        "    # smooth them by Gaussian\n",
        "    def _gauss_kernel(k=21, s=sigma):\n",
        "        ax = torch.arange(k, device=x.device) - (k-1)/2\n",
        "        ker = torch.exp(-(ax**2)/(2*s*s)); ker = ker/ker.sum()\n",
        "        return ker\n",
        "    k = 21\n",
        "    gx = _gauss_kernel(k).view(1,1,1,k)\n",
        "    gy = _gauss_kernel(k).view(1,1,k,1)\n",
        "    dx = F.conv2d(dx, gx, padding=(0,k//2)); dx = F.conv2d(dx, gy, padding=(k//2,0))\n",
        "    dy = F.conv2d(dy, gx, padding=(0,k//2)); dy = F.conv2d(dy, gy, padding=(k//2,0))\n",
        "    dx = dx.squeeze(0).squeeze(0) * alpha\n",
        "    dy = dy.squeeze(0).squeeze(0) * alpha\n",
        "\n",
        "    # grid in [-1,1]\n",
        "    yy, xx = torch.meshgrid(torch.linspace(-1,1,H,device=x.device),\n",
        "                            torch.linspace(-1,1,W,device=x.device), indexing='ij')\n",
        "    xx = (xx + dx / (W/2)).clamp(-1,1)\n",
        "    yy = (yy + dy / (H/2)).clamp(-1,1)\n",
        "    grid = torch.stack([xx, yy], dim=-1).unsqueeze(0)  # [1,H,W,2]\n",
        "    return F.grid_sample(x.unsqueeze(0), grid, mode='bilinear', padding_mode='border', align_corners=True).squeeze(0)\n",
        "\n",
        "# ---- Occlusion (domain-specific) ----\n",
        "def band_occlusion(x, mode='eyes', frac=0.18):\n",
        "    _, H, W = x.shape\n",
        "    band_h = max(1, int(frac*H))\n",
        "    y0 = {\n",
        "        'eyes': int(0.35*H) - band_h//2,\n",
        "        'mouth': int(0.75*H) - band_h//2,\n",
        "        'top': int(0.15*H) - band_h//2\n",
        "    }[mode]\n",
        "    y1 = max(0, y0); y2 = min(H, y0 + band_h)\n",
        "    x = x.clone()\n",
        "    x[:, y1:y2, :] = x[:, y1:y2, :].mean()  # neutral occluder (gray)\n",
        "    return x\n",
        "\n",
        "def localized_erasing(x, min_frac=0.01, max_frac=0.05):\n",
        "    C, H, W = x.shape\n",
        "    area = random.uniform(min_frac, max_frac) * H * W\n",
        "    side = int(max(2, math.sqrt(area)))\n",
        "    cx, cy = random.randint(0,W-1), random.randint(0,H-1)\n",
        "    x[:, max(0,cy-side//2):min(H,cy+side//2), max(0,cx-side//2):min(W,cx+side//2)] = 127.5\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3wTzPMWOygO"
      },
      "source": [
        "#Cell 11 — Augmentation Pipeline Builder (Curriculum; Output Normalized [-1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cxNGpw7nO1MI"
      },
      "outputs": [],
      "source": [
        "# ===== AugMixLite: blend multiple sub-policies with the original =====\n",
        "def _apply_bank(x, bank, k=2):\n",
        "    y = x.clone()\n",
        "    for _ in range(k):\n",
        "        op = random.choice(bank)\n",
        "        y = op(y)\n",
        "    return y\n",
        "\n",
        "def augmix_lite(x, banks, alpha=0.65, branches=2, depth=2):\n",
        "    mix = x.clone()\n",
        "    for _ in range(branches):\n",
        "        b = random.choice(banks)\n",
        "        y = _apply_bank(x, b, k=depth)\n",
        "        mix = mix + y\n",
        "    mix = mix / (branches + 1.0)\n",
        "    return (1 - alpha) * x + alpha * mix\n",
        "\n",
        "# ===== Advanced augmentation builder =====\n",
        "def build_advanced_fer_augment(strength: float):\n",
        "    \"\"\"\n",
        "    strength s in [0,1]: controls probabilities/magnitudes.\n",
        "    Returns f(x255->[1,H,W]) -> x_norm in [-1,1].\n",
        "    \"\"\"\n",
        "    s = float(max(0.0, min(1.0, strength)))\n",
        "    # Probabilities\n",
        "    p_photo = 0.7 * (0.5 + 0.5*s)\n",
        "    p_geom  = 0.6 * (0.5 + 0.5*s)\n",
        "    p_occl  = 0.40 * (0.5 + 0.5*s)\n",
        "    p_equal = 0.20 * s\n",
        "    p_blur  = 0.15 * s\n",
        "    # Magnitudes\n",
        "    gamma_rng = (0.85 - 0.15*s, 1.20 + 0.05*s)\n",
        "    contrast_scale = 0.20 + 0.10*s\n",
        "    jpeg_q = (55 - int(10*s), 85)\n",
        "    vignette_str = 0.15 + 0.20*s\n",
        "    elastic_alpha = 0.6 + 0.8*s\n",
        "    rot = 10 + 5*s\n",
        "    shear = 6 + 4*s\n",
        "    trans = 0.06 + 0.03*s\n",
        "    scale = 0.06 + 0.04*s\n",
        "\n",
        "    # Banks\n",
        "    photometric_bank = [\n",
        "        lambda z: gauss_noise(z, sigma=0.015 + 0.02*s),\n",
        "        lambda z: rand_gamma(z, *gamma_rng),\n",
        "        lambda z: rand_contrast(z, scale=contrast_scale),\n",
        "        lambda z: rand_jpeg(z, qmin=jpeg_q[0], qmax=jpeg_q[1]),\n",
        "        lambda z: rand_vignette(z, strength=vignette_str),\n",
        "    ]\n",
        "    geometric_bank = [\n",
        "        lambda z: rand_affine_small(z, max_rot=rot, max_trans=trans, max_shear=shear, max_scale=scale),\n",
        "        lambda z: rand_pad_crop(z, pad=3),\n",
        "        lambda z: rand_hflip(z, p=0.5),\n",
        "        lambda z: rand_elastic(z, alpha=elastic_alpha, sigma=4.0),\n",
        "    ]\n",
        "    occlusion_bank = [\n",
        "        lambda z: band_occlusion(z, mode='eyes',  frac=0.16 + 0.06*s),\n",
        "        lambda z: band_occlusion(z, mode='mouth', frac=0.16 + 0.06*s),\n",
        "        lambda z: band_occlusion(z, mode='top',   frac=0.14 + 0.06*s),\n",
        "        lambda z: localized_erasing(z, min_frac=0.01, max_frac=0.05),\n",
        "    ]\n",
        "    banks = [photometric_bank, geometric_bank, occlusion_bank]\n",
        "\n",
        "    def _norm_to_m11(x255):\n",
        "        x01 = (x255 / 255.0).clamp(0,1)\n",
        "        return (x01 - 0.5) * 2.0\n",
        "\n",
        "    def _augment(x):\n",
        "        # 1) pre-crop/pad + optional blur\n",
        "        if random.random() < p_geom:  x = rand_pad_crop(x, pad=3)\n",
        "        if random.random() < p_blur:  x = rand_blur(x, k=3)\n",
        "\n",
        "        # 2) photometric block\n",
        "        if random.random() < p_photo: x = random.choice(photometric_bank)(x)\n",
        "\n",
        "        # 3) AugMixLite composite (2 branches × depth=2)\n",
        "        x = augmix_lite(x, banks=banks, alpha=CONFIG.get(\"AUG_ALPHA\", 0.65),\n",
        "                        branches=2, depth=2)\n",
        "\n",
        "        # 4) more geometric and occlusion chance\n",
        "        if random.random() < p_geom:  x = random.choice(geometric_bank)(x)\n",
        "        if random.random() < p_occl:  x = random.choice(occlusion_bank)(x)\n",
        "\n",
        "        # 5) occasional histogram equalization near the end\n",
        "        if random.random() < p_equal: x = rand_equalize(x)\n",
        "\n",
        "        # Normalize to [-1,1] for the model\n",
        "        return _norm_to_m11(x)\n",
        "\n",
        "    return _augment\n",
        "\n",
        "# Keep legacy factory for fallback\n",
        "FER_AUG_FACTORY = build_advanced_fer_augment if CONFIG.get(\"USE_AUG_ADV\", False) else build_fer_augment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gQFbYZsO3nL"
      },
      "source": [
        "#Cell 12 — Augmentation Debug Cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XEOf68KO5Sp",
        "outputId": "8dc7476b-9813-4f94-c929-df6522976a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AugDebug] s=0.0: min=-1.000, max=0.978\n",
            "[AugDebug] s=0.5: min=-1.000, max=0.910\n",
            "[AugDebug] s=1.0: min=-1.000, max=1.000\n"
          ]
        }
      ],
      "source": [
        "if CONFIG[\"USE_AUG\"]:\n",
        "    xs, ys = next(iter(train_dl))\n",
        "    xs = xs[:8].to('cpu')\n",
        "    for s in [0.0, 0.5, 1.0]:\n",
        "        f = FER_AUG_FACTORY(s)\n",
        "        x_aug = torch.stack([f(x) for x in xs])  # [-1,1]\n",
        "        assert x_aug.shape == xs.shape and torch.isfinite(x_aug).all()\n",
        "        print(f\"[AugDebug] s={s}: min={x_aug.min().item():.3f}, max={x_aug.max().item():.3f}\")\n",
        "        # Optional quick glance\n",
        "        # grid = (x_aug * 0.5 + 0.5).clamp(0,1)\n",
        "        # grid = make_grid(grid, nrow=8)\n",
        "        # plt.figure(figsize=(12,3)); plt.axis('off'); plt.title(f'Advanced Aug s={s}')\n",
        "        # plt.imshow(grid.permute(1,2,0).squeeze(), cmap='gray'); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4ZRABSbO7ip"
      },
      "source": [
        "#Cell 13 — Metrics: Accuracy & Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0cCKIM2O-El",
        "outputId": "6066197e-e110-4758-af84-192953c151f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stage1] Class weights: [0.4800022542476654, 4.398185729980469, 0.4680519998073578, 0.26578086614608765, 0.39702051877975464, 0.6047332286834717, 0.3862254023551941]\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def accuracy(logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
        "    return (logits.argmax(dim=1) == targets).float().mean()\n",
        "\n",
        "def compute_class_weights(df) -> torch.Tensor:\n",
        "    counts = Counter(int(e) for e in df[\"emotion\"].tolist())\n",
        "    total = sum(counts.values())\n",
        "    weights = [total / max(1, counts.get(c, 1)) for c in range(7)]\n",
        "    w = torch.tensor(weights, dtype=torch.float32)\n",
        "    return w / w.mean()\n",
        "\n",
        "CLASS_WEIGHTS = compute_class_weights(tr_df)\n",
        "print(f\"[Stage1] Class weights: {CLASS_WEIGHTS.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFH8-w0iPAra"
      },
      "source": [
        "#Cell 14 — Losses: Label-Smoothed CE, Focal, Composite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bD7TSaSDPCpd"
      },
      "outputs": [],
      "source": [
        "# Replace your CompositeLoss with this “SmoothedFocal” preset.\n",
        "class LabelSmoothingCE(nn.Module):\n",
        "    def __init__(self, eps=0.10, reduction='mean'):\n",
        "        super().__init__(); self.eps=eps; self.reduction=reduction\n",
        "    def forward(self, logits, targets):\n",
        "        n = logits.size(-1)\n",
        "        logp = F.log_softmax(logits, dim=-1)\n",
        "        with torch.no_grad():\n",
        "            true = torch.zeros_like(logp).fill_(self.eps/(n-1))\n",
        "            true.scatter_(1, targets.unsqueeze(1), 1.0 - self.eps)\n",
        "        loss = -(true * logp).sum(dim=1)\n",
        "        return loss.mean() if self.reduction=='mean' else loss\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=1.5, reduction='mean'):\n",
        "        super().__init__(); self.g=gamma; self.reduction=reduction\n",
        "    def forward(self, logits, targets):\n",
        "        ce = F.cross_entropy(logits, targets, reduction='none')\n",
        "        pt = torch.exp(-ce)\n",
        "        fl = ((1-pt)**self.g) * ce\n",
        "        return fl.mean() if self.reduction=='mean' else fl\n",
        "\n",
        "class SmoothedFocal(nn.Module):\n",
        "    def __init__(self, eps=0.10, gamma=1.5, alpha=0.70, weight=None):\n",
        "        super().__init__(); self.a=alpha; self.w = weight\n",
        "        self.lsce = LabelSmoothingCE(eps)\n",
        "        self.focal= FocalLoss(gamma)\n",
        "    def forward(self, logits, targets):\n",
        "        if self.w is not None:\n",
        "            # weight affects CE inside focal; apply by hand\n",
        "            ce = F.cross_entropy(logits, targets, reduction='none', weight=self.w.to(logits.device))\n",
        "            pt = torch.exp(-ce); fl = ((1-pt)**1.5) * ce\n",
        "            ls = self.lsce(logits, targets)\n",
        "            return self.a*ls + (1-self.a)*fl.mean()\n",
        "        return self.a*self.lsce(logits, targets) + (1-self.a)*self.focal(logits, targets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZvGD2yRPD-B"
      },
      "source": [
        "#Cell 15 — MixUp & CutMix Utilities + Mixed Criterion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "V_GdzW7CPG1_"
      },
      "outputs": [],
      "source": [
        "def mixup_data(x, y, alpha=0.2):\n",
        "    if alpha <= 0.0:\n",
        "        return x, y, 1.0, None\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    index = torch.randperm(x.size(0), device=x.device)\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, (y_a, y_b), lam, index\n",
        "\n",
        "def cutmix_data(x, y, alpha=1.0, min_lam=0.3, max_lam=0.7):\n",
        "    if alpha <= 0.0:\n",
        "        return x, y, 1.0, None\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    lam = float(max(min_lam, min(max_lam, lam)))\n",
        "    B, C, H, W = x.size()\n",
        "    index = torch.randperm(B, device=x.device)\n",
        "    cut_w = int(W * math.sqrt(1 - lam))\n",
        "    cut_h = int(H * math.sqrt(1 - lam))\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "    x1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    x2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    y1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    y2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "    x[:, :, y1:y2, x1:x2] = x[index, :, y1:y2, x1:x2]\n",
        "    lam = 1 - ((x2 - x1) * (y2 - y1) / (W * H + 1e-9))\n",
        "    y_a, y_b = y, y[index]\n",
        "    return x, (y_a, y_b), lam, index\n",
        "\n",
        "def mixed_criterion(criterion, logits, targets_mix, lam):\n",
        "    if isinstance(targets_mix, tuple):\n",
        "        y_a, y_b = targets_mix\n",
        "        return lam * criterion(logits, y_a) + (1 - lam) * criterion(logits, y_b)\n",
        "    else:\n",
        "        return criterion(logits, targets_mix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikjEOYF6PMce"
      },
      "source": [
        "#Cell 16 — EMA (Exponential Moving Average) for Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Aux44u9ePPhv"
      },
      "outputs": [],
      "source": [
        "class EMA:\n",
        "    def __init__(self, model: nn.Module, decay: float = 0.999):\n",
        "        self.decay = float(decay)\n",
        "        self.shadow = {}\n",
        "        self.backup = {}\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name] = param.data.clone()\n",
        "\n",
        "    def update(self, model: nn.Module):\n",
        "        for name, param in model.named_parameters():\n",
        "            if not param.requires_grad:\n",
        "                continue\n",
        "            self.shadow[name] = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]\n",
        "\n",
        "    def apply_shadow(self, model: nn.Module):\n",
        "        self.backup = {}\n",
        "        for name, param in model.named_parameters():\n",
        "            if not param.requires_grad:\n",
        "                continue\n",
        "            self.backup[name] = param.data.clone()\n",
        "            param.data = self.shadow[name].clone()\n",
        "\n",
        "    def restore(self, model: nn.Module):\n",
        "        for name, param in model.named_parameters():\n",
        "            if not param.requires_grad:\n",
        "                continue\n",
        "            param.data = self.backup[name].clone()\n",
        "        self.backup = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jrmj1e_PQwd"
      },
      "source": [
        "#Cell 17 — Base Training/Evaluation Mixin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nknmYGNnPTGM"
      },
      "outputs": [],
      "source": [
        "class TrainingMixin:\n",
        "    def training_step(self, batch, criterion):\n",
        "        x, y = batch\n",
        "        x, y = x.to(self.device), y.to(self.device)\n",
        "        logits = self(x)\n",
        "        loss = criterion(logits, y)\n",
        "        return loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def validation_step(self, batch, criterion):\n",
        "        x, y = batch\n",
        "        x, y = x.to(self.device), y.to(self.device)\n",
        "        logits = self(x)\n",
        "        loss = criterion(logits, y)\n",
        "        acc = accuracy(logits, y)\n",
        "        return loss.detach(), acc.detach()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def evaluate_loader(self, loader, criterion):\n",
        "        self.eval()\n",
        "        losses, accs = [], []\n",
        "        for batch in loader:\n",
        "            l, a = self.validation_step(batch, criterion)\n",
        "            losses.append(l.item()); accs.append(a.item())\n",
        "        return float(np.mean(losses)), float(np.mean(accs))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ymRPHafPUZs"
      },
      "source": [
        "#Cell 18 — Training Hyperparameters & Global Knobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oUfKVzEPW9Z",
        "outputId": "243ec7db-fc8a-4599-f3d2-d7165249590a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stage1] HP snapshot: {'EPOCHS': 70, 'LR': 0.0003, 'WD': 5e-05, 'WARMUP_EPOCHS': 4, 'LR_MIN': 5e-05, 'PATIENCE': 18, 'EMA_DECAY': 0.9995, 'MIXUP_ALPHA': 0.3, 'CUTMIX_ALPHA': 1.0, 'AUG_RAMP_EPOCHS': 0.25}\n"
          ]
        }
      ],
      "source": [
        "# === Squeezed HP (late-improvement friendly) ===\n",
        "HP = {\n",
        "    \"EPOCHS\": 70,          # give the cosine tail more room\n",
        "    \"LR\": 3e-4,            # good starting LR for AdamW fine-tune\n",
        "    \"WD\": 5e-5,            # was 1e-4; slightly lower to reduce underfit in the tail\n",
        "    \"WARMUP_EPOCHS\": 4,    # keep warmup\n",
        "    \"LR_MIN\": 5e-5,        # raise tail floor so updates don’t die out (you were still learning at ~3e-5)\n",
        "    \"PATIENCE\": 18,        # was 8; your run was still improving at ep40 → avoid premature stop\n",
        "    \"EMA_DECAY\": 0.9995,   # a touch slower EMA helps late stability\n",
        "    \"MIXUP_ALPHA\": 0.3,\n",
        "    \"CUTMIX_ALPHA\": 1.0,\n",
        "    \"AUG_RAMP_EPOCHS\": 0.25, # ramp a bit faster; we’ll taper later anyway\n",
        "}\n",
        "print(\"[Stage1] HP snapshot:\", HP)\n",
        "\n",
        "# --- Late-phase tweaks (outside HP; keep your existing fit(...) call) ---\n",
        "# Use these variables if your training loop supports them; otherwise just apply the logic in code.\n",
        "P_MIX, P_CUT = 0.30, 0.30           # keep some mixing early\n",
        "TAPER_START_FRAC, TAPER_END_FRAC = 0.60, 0.90   # linearly taper mix/aug to ~0 by last 10%\n",
        "LABEL_SMOOTH_EPS = 0.05             # feed into your loss if supported (CrossEntropy w/ label smoothing)\n",
        "\n",
        "# Example (conceptual) inside your epoch loop:\n",
        "# frac = epoch / HP[\"EPOCHS\"]\n",
        "# p_mix_now = P_MIX if frac < TAPER_START_FRAC else max(0.0, P_MIX * (1 - (frac - TAPER_START_FRAC) / (TAPER_END_FRAC - TAPER_START_FRAC)))\n",
        "# p_cut_now = P_CUT if frac < TAPER_START_FRAC else max(0.0, P_CUT * (1 - (frac - TAPER_START_FRAC) / (TAPER_END_FRAC - TAPER_START_FRAC)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0E74WzYPYh3"
      },
      "source": [
        "#Cell 19 — CBAM Block (Attention Module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eUopqauqPbdt"
      },
      "outputs": [],
      "source": [
        "class CBAM(nn.Module):\n",
        "    def __init__(self, ch, r=8):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Conv2d(ch, max(1, ch//r), 1, bias=True), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(max(1, ch//r), ch, 1, bias=True)\n",
        "        )\n",
        "        self.spatial = nn.Sequential(\n",
        "            nn.Conv2d(2, 1, kernel_size=7, padding=3, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        ca = F.adaptive_avg_pool2d(x, 1) + F.adaptive_max_pool2d(x, 1)\n",
        "        ca = self.sigmoid(self.mlp(ca))\n",
        "        x = x * ca\n",
        "        ms = torch.cat([x.mean(1, keepdim=True), x.max(1, keepdim=True)[0]], dim=1)\n",
        "        sa = self.spatial(ms)\n",
        "        return x * sa\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp3IswFBPcx7"
      },
      "source": [
        "#Cell 20 — Optional Sobel Stem (for Grayscale Edges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "s6AxJfsjPe89"
      },
      "outputs": [],
      "source": [
        "class SobelStem(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        kernel_x = torch.tensor([[1,0,-1],[2,0,-2],[1,0,-1]], dtype=torch.float32)\n",
        "        kernel_y = torch.tensor([[1,2,1],[0,0,0],[-1,-2,-1]], dtype=torch.float32)\n",
        "        self.register_buffer('kx', kernel_x.view(1,1,3,3))\n",
        "        self.register_buffer('ky', kernel_y.view(1,1,3,3))\n",
        "    def forward(self, x):\n",
        "        gx = F.conv2d(x, self.kx, padding=1)\n",
        "        gy = F.conv2d(x, self.ky, padding=1)\n",
        "        g = torch.sqrt(gx**2 + gy**2 + 1e-6)\n",
        "        return torch.cat([x, g], dim=1)  # [B,2,H,W]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER92xzPAPga2"
      },
      "source": [
        "#Cell 21 — HybridEffNet Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Tvrj2UVTPkkw"
      },
      "outputs": [],
      "source": [
        "# ===== Cell 21 — HybridEffNet Model Definition (REPLACE) =====\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "\n",
        "# Pull optional knobs from CONFIG with safe defaults\n",
        "CLASSIFIER_DROPOUT = float(CONFIG.get(\"CLASSIFIER_DROPOUT\", 0.30))\n",
        "USE_CBAM = bool(CONFIG.get(\"USE_CBAM\", True))  # keep True to match prior runs\n",
        "\n",
        "class SobelLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        kx = torch.tensor([[1,0,-1],[2,0,-2],[1,0,-1]], dtype=torch.float32)\n",
        "        ky = torch.tensor([[1,2,1],[0,0,0],[-1,-2,-1]], dtype=torch.float32)\n",
        "        w  = torch.stack([kx, ky]).unsqueeze(1)  # (2,1,3,3)\n",
        "        self.register_buffer('w', w)\n",
        "\n",
        "    def forward(self, x):            # x:[B,1,H,W]\n",
        "        edges = F.conv2d(x, self.w, padding=1)   # [B,2,H,W]\n",
        "        return torch.cat([x, edges], dim=1)      # [B,3,H,W]\n",
        "\n",
        "class HybridEffNet(nn.Module, TrainingMixin):\n",
        "    def __init__(self, num_classes=7, classifier_dropout=CLASSIFIER_DROPOUT, use_cbam=USE_CBAM):\n",
        "        super().__init__()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        base = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
        "\n",
        "        # Sobel expands 1→3 channels so we can keep EfficientNet stem unchanged\n",
        "        self.sobel    = SobelLayer()\n",
        "        self.features = base.features\n",
        "        self.pool     = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Optional CBAM on the final feature map (requires Cell 19)\n",
        "        self.cbam = CBAM(1280) if use_cbam else None\n",
        "\n",
        "        in_features = 1280  # EfficientNet-B0 penultimate dim\n",
        "        self.bn   = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=classifier_dropout)\n",
        "        self.head = nn.Linear(in_features, num_classes)\n",
        "\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, x1):           # x1 in [-1,1], shape [B,1,H,W]\n",
        "        x3 = self.sobel(x1)          # [B,3,H,W]\n",
        "        f  = self.features(x3)       # [B,1280,h,w]\n",
        "        if self.cbam is not None:\n",
        "            f = self.cbam(f)\n",
        "        f  = self.pool(f).flatten(1) # [B,1280]\n",
        "        f  = self.bn(f)\n",
        "        f  = self.drop(f)\n",
        "        return self.head(f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU_ywDDUPmB4"
      },
      "source": [
        "#Cell 22 — Optimizer, Warmup-Cosine Scheduler, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mYHbUtgmPn9I"
      },
      "outputs": [],
      "source": [
        "def make_adamw(params, lr, wd):\n",
        "    return torch.optim.AdamW(params, lr=lr, weight_decay=wd)\n",
        "\n",
        "class WarmupCosine:\n",
        "    def __init__(self, optimizer, warmup_epochs, max_epochs, lr_min=1e-6, lr_max=None):\n",
        "        self.opt = optimizer\n",
        "        self.warmup = max(1, int(warmup_epochs))\n",
        "        self.maxe = int(max_epochs)\n",
        "        self.t = 0\n",
        "        self.lr_min = lr_min\n",
        "        self.lr_max = lr_max if lr_max is not None else max(g['lr'] for g in optimizer.param_groups)\n",
        "    def step(self):\n",
        "        self.t += 1\n",
        "        if self.t <= self.warmup:\n",
        "            lr = self.lr_min + (self.lr_max - self.lr_min) * (self.t / self.warmup)\n",
        "        else:\n",
        "            tt = (self.t - self.warmup) / max(1, (self.maxe - self.warmup))\n",
        "            lr = self.lr_min + 0.5*(self.lr_max - self.lr_min)*(1 + math.cos(math.pi*tt))\n",
        "        for g in self.opt.param_groups:\n",
        "            g['lr'] = lr\n",
        "        return lr\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=8, min_delta=1e-4):\n",
        "        self.patience = int(patience)\n",
        "        self.min_delta = float(min_delta)\n",
        "        self.best = float('inf')\n",
        "        self.bad = 0\n",
        "    def step(self, val_loss):\n",
        "        if val_loss < self.best - self.min_delta:\n",
        "            self.best = val_loss\n",
        "            self.bad = 0\n",
        "            return False\n",
        "        self.bad += 1\n",
        "        return self.bad >= self.patience\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z9WyhD3PpUd"
      },
      "source": [
        "#Cell 23 — fit_with_aug(): Training Loop with Aug/Mix/EMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SlOTFD_yPrxa"
      },
      "outputs": [],
      "source": [
        "# === Cell 23 — fit_with_aug(): advanced aug + late-phase taper + AMP + EMA ===\n",
        "def fit_with_aug(model: nn.Module, train_dl, valid_dl, hp, config):\n",
        "    device = model.device\n",
        "\n",
        "    # Loss with class weights (computed earlier)\n",
        "    weight = CLASS_WEIGHTS.to(device)\n",
        "    criterion = SmoothedFocal(eps=0.10, gamma=1.5, alpha=0.70, weight=weight)\n",
        "\n",
        "    # Optimizer / Scheduler / EarlyStop / EMA / AMP\n",
        "    opt   = make_adamw(model.parameters(), lr=hp[\"LR\"], wd=hp[\"WD\"])\n",
        "    sched = WarmupCosine(opt, warmup_epochs=hp[\"WARMUP_EPOCHS\"],\n",
        "                         max_epochs=hp[\"EPOCHS\"], lr_min=hp[\"LR_MIN\"])\n",
        "    stopper = EarlyStopping(patience=hp[\"PATIENCE\"], min_delta=1e-4)\n",
        "    ema   = EMA(model, decay=hp[\"EMA_DECAY\"]) if config[\"USE_EMA\"] else None\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
        "\n",
        "    # Curriculum ramp for augmentation strength\n",
        "    total_epochs  = int(hp[\"EPOCHS\"])\n",
        "    aug_ramp_frac = float(hp.get(\"AUG_RAMP_EPOCHS\", 0.30))\n",
        "    ramp_epochs   = max(1, int(aug_ramp_frac * total_epochs))\n",
        "\n",
        "    # Feature flags for late-phase controls\n",
        "    cap_late   = bool(config.get(\"AUG_CAP_LATE\", True))\n",
        "    taper_late = bool(config.get(\"TAPER_MIX_LATE\", True))\n",
        "\n",
        "    history = []\n",
        "    best_val = float(\"inf\")  # track best val_loss for reference/logging\n",
        "\n",
        "    for epoch in range(1, total_epochs + 1):\n",
        "        model.train()\n",
        "        epoch_loss_sum = 0.0\n",
        "        num_seen = 0\n",
        "\n",
        "        # ----- Build augmentation for this epoch -----\n",
        "        if config[\"USE_AUG\"]:\n",
        "            # curriculum strength in [0.2, 0.8]\n",
        "            s = 0.2 + 0.6 * min(1.0, epoch / ramp_epochs)\n",
        "            # optional cap in the final 30% to better match val distribution\n",
        "            if cap_late and epoch >= int(0.7 * total_epochs):\n",
        "                s = min(s, 0.6)\n",
        "            augment = FER_AUG_FACTORY(s)\n",
        "        else:\n",
        "            augment = None\n",
        "\n",
        "        # ----- Late-phase taper for mixing (MixUp/CutMix) -----\n",
        "        mixup_alpha  = float(hp[\"MIXUP_ALPHA\"])\n",
        "        cutmix_alpha = float(hp[\"CUTMIX_ALPHA\"])\n",
        "        use_cutmix   = bool(config[\"USE_CUTMIX\"])\n",
        "\n",
        "        if taper_late and epoch >= int(0.5 * total_epochs):\n",
        "            mixup_alpha  = max(0.1, mixup_alpha * 0.5)   # softer mixing\n",
        "            cutmix_alpha = max(0.5, cutmix_alpha * 0.5) # smaller boxes\n",
        "        if taper_late and epoch >= int(0.7 * total_epochs):\n",
        "            use_cutmix = False  # sharpen decision boundaries late\n",
        "\n",
        "        # ===================== Train loop =====================\n",
        "        for xb, yb in train_dl:\n",
        "            xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
        "\n",
        "            # Apply augmentation or deterministic normalization\n",
        "            if augment is not None:\n",
        "                # advanced policy returns tensors already normalized to [-1,1]\n",
        "                xb = torch.stack([augment(x) for x in xb])  # [-1,1]\n",
        "            else:\n",
        "                xb = ((xb / 255.0) - 0.5) * 2.0\n",
        "\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "\n",
        "            with torch.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=torch.cuda.is_available()):\n",
        "                if config[\"USE_MIXUP\"] or use_cutmix:\n",
        "                    if use_cutmix and random.random() < 0.5:\n",
        "                        xb, targets_mix, lam, _ = cutmix_data(\n",
        "                            xb, yb, alpha=cutmix_alpha, min_lam=0.3, max_lam=0.7\n",
        "                        )\n",
        "                    else:\n",
        "                        xb, targets_mix, lam, _ = mixup_data(xb, yb, alpha=mixup_alpha)\n",
        "                    logits = model(xb)\n",
        "                    loss   = mixed_criterion(criterion, logits, targets_mix, lam)\n",
        "                else:\n",
        "                    logits = model(xb)\n",
        "                    loss   = criterion(logits, yb)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            if torch.cuda.is_available():\n",
        "                scaler.unscale_(opt)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "\n",
        "            if ema is not None:\n",
        "                ema.update(model)\n",
        "\n",
        "            bs = xb.size(0)\n",
        "            epoch_loss_sum += loss.item() * bs\n",
        "            num_seen += bs\n",
        "\n",
        "        # ===================== Validation =====================\n",
        "        @torch.no_grad()\n",
        "        def _eval(loader):\n",
        "            model.eval()\n",
        "            losses, accs = [], []\n",
        "            for xb, yb in loader:\n",
        "                xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
        "                xb = ((xb / 255.0) - 0.5) * 2.0  # eval is augmentation-free\n",
        "                logits = model(xb)\n",
        "                l = criterion(logits, yb)\n",
        "                a = accuracy(logits, yb)\n",
        "                losses.append(l.item()); accs.append(a.item())\n",
        "            return float(np.mean(losses)), float(np.mean(accs))\n",
        "\n",
        "        val_loss, val_acc = _eval(valid_dl)\n",
        "\n",
        "        # Scheduler step after seeing validation\n",
        "        lr_now = sched.step()\n",
        "\n",
        "        # Epoch bookkeeping\n",
        "        train_loss = epoch_loss_sum / max(1, num_seen)\n",
        "        history.append({\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_acc\": val_acc,\n",
        "            \"lr\": lr_now\n",
        "        })\n",
        "\n",
        "        # Logging with best marker on val_loss (early stop follows this)\n",
        "        is_best = \"\"\n",
        "        if val_loss < best_val - 1e-6:\n",
        "            best_val = val_loss\n",
        "            is_best = \" *best*\"\n",
        "        print(f\"[Epoch {epoch:03d}/{total_epochs}] \"\n",
        "              f\"train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  \"\n",
        "              f\"val_acc={val_acc:.4f}  lr={lr_now:.2e}{is_best}\")\n",
        "\n",
        "        # Early stopping on validation loss\n",
        "        if stopper.step(val_loss):\n",
        "            print(\"[EarlyStopping] Patience exhausted; stopping training.\")\n",
        "            break\n",
        "\n",
        "    return history, ema\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KE1e7ExPtTP"
      },
      "source": [
        "#Cell 24 — Integration Debug: One Forward/Backward Probe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4_cgoJ2PwbQ",
        "outputId": "03f13a60-8daf-4142-fe3f-83fa1347cb35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 141MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Probe] model params ≈ 4.43M, device=cuda\n",
            "[Probe] logits=(192, 7), loss=2.1656, grad_head_norm=3.032\n"
          ]
        }
      ],
      "source": [
        "# Build the model exactly as we intend to train/evaluate it.\n",
        "# Assumes HybridEffNet(num_classes=7, classifier_dropout=0.30, use_cbam=True) from Cell 21.\n",
        "\n",
        "model = HybridEffNet(num_classes=7, classifier_dropout=0.30, use_cbam=True)\n",
        "model.train()\n",
        "\n",
        "# Quick param count banner\n",
        "total_params = sum(p.numel() for p in model.parameters()) / 1e6\n",
        "print(f\"[Probe] model params ≈ {total_params:.2f}M, device={model.device}\")\n",
        "\n",
        "# One mini-batch probe (sanity check on shapes, loss, and gradients)\n",
        "xb, yb = next(iter(train_dl))\n",
        "xb, yb = xb.to(model.device), yb.to(model.device)\n",
        "\n",
        "# Deterministic normalization for the probe (no augmentation here)\n",
        "xb = ((xb / 255.0) - 0.5) * 2.0\n",
        "\n",
        "# Mixed precision probe if CUDA is available\n",
        "model.zero_grad(set_to_none=True)\n",
        "with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=torch.cuda.is_available()):\n",
        "    logits = model(xb)\n",
        "    loss   = F.cross_entropy(logits, yb)\n",
        "\n",
        "loss.backward()\n",
        "head_grad_norm = model.head.weight.grad.norm().item()\n",
        "print(f\"[Probe] logits={tuple(logits.shape)}, loss={loss.item():.4f}, grad_head_norm={head_grad_norm:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CljeZ8RPyPk"
      },
      "source": [
        "#Cell 25 — Launch Training (FER-only Path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpsSwTOYP0-d",
        "outputId": "dc49c516-ae50-4687-8fea-88758c03aa37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stage3] Starting training…\n",
            "[Epoch 001/70] train_loss=1.4763  val_loss=1.2285  val_acc=0.4506  lr=1.12e-04 *best*\n",
            "[Epoch 002/70] train_loss=1.3703  val_loss=1.1638  val_acc=0.4867  lr=1.75e-04 *best*\n",
            "[Epoch 003/70] train_loss=1.3286  val_loss=1.1130  val_acc=0.5229  lr=2.37e-04 *best*\n",
            "[Epoch 004/70] train_loss=1.3095  val_loss=1.0740  val_acc=0.5462  lr=3.00e-04 *best*\n",
            "[Epoch 005/70] train_loss=1.2607  val_loss=1.0314  val_acc=0.5633  lr=3.00e-04 *best*\n",
            "[Epoch 006/70] train_loss=1.2619  val_loss=1.0262  val_acc=0.5782  lr=2.99e-04 *best*\n",
            "[Epoch 007/70] train_loss=1.2251  val_loss=0.9901  val_acc=0.5967  lr=2.99e-04 *best*\n",
            "[Epoch 008/70] train_loss=1.2309  val_loss=0.9807  val_acc=0.6066  lr=2.98e-04 *best*\n",
            "[Epoch 009/70] train_loss=1.1971  val_loss=0.9548  val_acc=0.6149  lr=2.96e-04 *best*\n",
            "[Epoch 010/70] train_loss=1.1863  val_loss=0.9519  val_acc=0.6227  lr=2.95e-04 *best*\n",
            "[Epoch 011/70] train_loss=1.1606  val_loss=0.9327  val_acc=0.6333  lr=2.93e-04 *best*\n",
            "[Epoch 012/70] train_loss=1.1735  val_loss=0.9444  val_acc=0.6338  lr=2.91e-04\n",
            "[Epoch 013/70] train_loss=1.1680  val_loss=0.9543  val_acc=0.6419  lr=2.89e-04\n",
            "[Epoch 014/70] train_loss=1.1460  val_loss=0.9300  val_acc=0.6458  lr=2.86e-04 *best*\n",
            "[Epoch 015/70] train_loss=1.1495  val_loss=0.9110  val_acc=0.6482  lr=2.83e-04 *best*\n",
            "[Epoch 016/70] train_loss=1.1363  val_loss=0.9118  val_acc=0.6511  lr=2.80e-04\n",
            "[Epoch 017/70] train_loss=1.1489  val_loss=0.9070  val_acc=0.6577  lr=2.77e-04 *best*\n",
            "[Epoch 018/70] train_loss=1.1228  val_loss=0.9258  val_acc=0.6535  lr=2.73e-04\n",
            "[Epoch 019/70] train_loss=1.1495  val_loss=0.9068  val_acc=0.6634  lr=2.69e-04 *best*\n",
            "[Epoch 020/70] train_loss=1.1385  val_loss=0.9064  val_acc=0.6649  lr=2.65e-04 *best*\n",
            "[Epoch 021/70] train_loss=1.1241  val_loss=0.8930  val_acc=0.6688  lr=2.61e-04 *best*\n",
            "[Epoch 022/70] train_loss=1.0895  val_loss=0.8881  val_acc=0.6718  lr=2.57e-04 *best*\n",
            "[Epoch 023/70] train_loss=1.1166  val_loss=0.8823  val_acc=0.6780  lr=2.52e-04 *best*\n",
            "[Epoch 024/70] train_loss=1.1024  val_loss=0.8886  val_acc=0.6799  lr=2.48e-04\n",
            "[Epoch 025/70] train_loss=1.1112  val_loss=0.8976  val_acc=0.6769  lr=2.43e-04\n",
            "[Epoch 026/70] train_loss=1.1225  val_loss=0.8966  val_acc=0.6779  lr=2.37e-04\n",
            "[Epoch 027/70] train_loss=1.0682  val_loss=0.8811  val_acc=0.6837  lr=2.32e-04 *best*\n",
            "[Epoch 028/70] train_loss=1.0996  val_loss=0.8895  val_acc=0.6816  lr=2.27e-04\n",
            "[Epoch 029/70] train_loss=1.0828  val_loss=0.8880  val_acc=0.6756  lr=2.21e-04\n",
            "[Epoch 030/70] train_loss=1.0970  val_loss=0.8755  val_acc=0.6844  lr=2.16e-04 *best*\n",
            "[Epoch 031/70] train_loss=1.0618  val_loss=0.8875  val_acc=0.6870  lr=2.10e-04\n",
            "[Epoch 032/70] train_loss=1.0381  val_loss=0.8698  val_acc=0.6883  lr=2.04e-04 *best*\n",
            "[Epoch 033/70] train_loss=1.0454  val_loss=0.8639  val_acc=0.6921  lr=1.99e-04 *best*\n",
            "[Epoch 034/70] train_loss=1.0412  val_loss=0.8767  val_acc=0.6839  lr=1.93e-04\n",
            "[Epoch 035/70] train_loss=1.0112  val_loss=0.8697  val_acc=0.6932  lr=1.87e-04\n",
            "[Epoch 036/70] train_loss=1.0008  val_loss=0.8649  val_acc=0.6917  lr=1.81e-04\n",
            "[Epoch 037/70] train_loss=0.9886  val_loss=0.8594  val_acc=0.6943  lr=1.75e-04 *best*\n",
            "[Epoch 038/70] train_loss=0.9485  val_loss=0.8605  val_acc=0.6979  lr=1.69e-04\n",
            "[Epoch 039/70] train_loss=1.0194  val_loss=0.8697  val_acc=0.6994  lr=1.63e-04\n",
            "[Epoch 040/70] train_loss=0.9956  val_loss=0.8690  val_acc=0.6862  lr=1.57e-04\n",
            "[Epoch 041/70] train_loss=0.9793  val_loss=0.8683  val_acc=0.6870  lr=1.51e-04\n",
            "[Epoch 042/70] train_loss=0.9458  val_loss=0.8671  val_acc=0.6924  lr=1.46e-04\n",
            "[Epoch 043/70] train_loss=0.9587  val_loss=0.8616  val_acc=0.6943  lr=1.40e-04\n",
            "[Epoch 044/70] train_loss=0.9862  val_loss=0.8736  val_acc=0.6937  lr=1.34e-04\n",
            "[Epoch 045/70] train_loss=0.9471  val_loss=0.8711  val_acc=0.6982  lr=1.29e-04\n",
            "[Epoch 046/70] train_loss=0.9787  val_loss=0.8651  val_acc=0.7004  lr=1.23e-04\n",
            "[Epoch 047/70] train_loss=0.9471  val_loss=0.8659  val_acc=0.6972  lr=1.18e-04\n",
            "[Epoch 048/70] train_loss=0.9515  val_loss=0.8684  val_acc=0.6992  lr=1.13e-04\n",
            "[Epoch 049/70] train_loss=0.6925  val_loss=0.8873  val_acc=0.6964  lr=1.07e-04\n",
            "[Epoch 050/70] train_loss=0.7469  val_loss=0.8860  val_acc=0.6907  lr=1.02e-04\n",
            "[Epoch 051/70] train_loss=0.6981  val_loss=0.8802  val_acc=0.6952  lr=9.77e-05\n",
            "[Epoch 052/70] train_loss=0.6960  val_loss=0.8829  val_acc=0.6936  lr=9.31e-05\n",
            "[Epoch 053/70] train_loss=0.6850  val_loss=0.8902  val_acc=0.6994  lr=8.87e-05\n",
            "[Epoch 054/70] train_loss=0.7088  val_loss=0.8968  val_acc=0.6935  lr=8.45e-05\n",
            "[Epoch 055/70] train_loss=0.7051  val_loss=0.8847  val_acc=0.6959  lr=8.05e-05\n",
            "[EarlyStopping] Patience exhausted; stopping training.\n"
          ]
        }
      ],
      "source": [
        "# Trains with the current switches and HP (keeps your dict name \"HP\").\n",
        "# Uses EMA if CONFIG[\"USE_EMA\"] is True; history and ema_obj are returned\n",
        "# from fit_with_aug() and can be reused by evaluation cells.\n",
        "\n",
        "if CONFIG[\"RUN_FER\"] and not CONFIG[\"DRY_RUN\"]:\n",
        "    print(\"[Stage3] Starting training…\")\n",
        "    history, ema_obj = fit_with_aug(model, train_dl, valid_dl, HP, CONFIG)\n",
        "else:\n",
        "    print(\"[Stage3] Skipping training due to DRY_RUN or RUN_FER=False.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJFgErAOP4-u"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A) Does history say we ever reached ~0.70 on VAL?\n",
        "best_hist_val = max([h.get('val_acc', float('-inf')) for h in history]) if 'history' in globals() else None\n",
        "print(\"history_best_val =\", best_hist_val)\n",
        "\n",
        "# B) Are we holding the best checkpoint weights?\n",
        "#    If you saved to SAVE_BEST_PATH earlier, load it now.\n",
        "from pathlib import Path\n",
        "if 'SAVE_BEST_PATH' in globals() and Path(SAVE_BEST_PATH).exists():\n",
        "    ckpt = torch.load(SAVE_BEST_PATH, map_location='cpu')\n",
        "    model.load_state_dict(ckpt['model_state'])\n",
        "    model.to(next(iter(model.parameters())).device)\n",
        "    print(\"Reloaded model from\", SAVE_BEST_PATH)\n",
        "else:\n",
        "    print(\"WARNING: best checkpoint not found. Make sure you didn't re‑init the model.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQNqaxRg64dq",
        "outputId": "91f19556-9bca-4a5b-d344-cd4e1ce680d6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "history_best_val = 0.7004484057426452\n",
            "WARNING: best checkpoint not found. Make sure you didn't re‑init the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Should print ~0.69–0.70 if everything else is consistent\n",
        "val_acc_now = eval_top1(model, valid_dl)\n",
        "print(\"val_acc_now =\", val_acc_now)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "0JUhNiup6myM",
        "outputId": "dbdf2462-86d2-4b7a-8f76-4254663b0f94"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "DataLoader worker (pid(s) 1223, 1224, 1225, 1226, 1227, 1228) exited unexpectedly",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEmpty\u001b[0m: ",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3499216599.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Should print ~0.69–0.70 if everything else is consistent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mval_acc_now\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_top1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val_acc_now =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_now\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-234460889.py\u001b[0m in \u001b[0;36meval_top1\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_reset\u001b[0;34m(self, loader, first_iter)\u001b[0m\n\u001b[1;32m   1262\u001b[0m             \u001b[0mresume_iteration_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_workers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mresume_iteration_cnt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m                 \u001b[0mreturn_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ResumeIteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0mreturn_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                 raise RuntimeError(\n\u001b[0m\u001b[1;32m   1299\u001b[0m                     \u001b[0;34mf\"DataLoader worker (pid(s) {pids_str}) exited unexpectedly\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                 ) from e\n",
            "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 1223, 1224, 1225, 1226, 1227, 1228) exited unexpectedly"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#25B"
      ],
      "metadata": {
        "id": "z9L7jrxtoaho"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nEjAjiWj9qRl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#25B"
      ],
      "metadata": {
        "id": "cN7V8sAMoXwU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iYJlISHaokxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install fvcore\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3oGLBrt-O0V",
        "outputId": "0631dc89-d95b-4bf6-bf78-1f9b5127e6f4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fvcore) (2.0.2)\n",
            "Collecting yacs>=0.1.6 (from fvcore)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from fvcore) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (from fvcore) (3.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from fvcore) (11.3.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from fvcore) (0.9.0)\n",
            "Collecting iopath>=0.1.7 (from fvcore)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from iopath>=0.1.7->fvcore) (4.14.1)\n",
            "Collecting portalocker (from iopath>=0.1.7->fvcore)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=0f85255d665f176222de2f09a2bd1162ddae987a0128523f9a018197f4a6a80c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/9f/a5/e4f5b27454ccd4596bd8b62432c7d6b1ca9fa22aef9d70a16a\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=6f44f541dd6d6d1e6068a08226b10680272e44337e5ce8632dbc4a2078cf05a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/96/04/4f5f31ff812f684f69f40cb1634357812220aac58d4698048c\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.2.0 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "===== Cell 28 — FLOPs (auto‑install fvcore) ====="
      ],
      "metadata": {
        "id": "m-WLKO-0-Xdk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bqE-xP8B-XMk"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "===== Cell 29 — Efficiency report ====="
      ],
      "metadata": {
        "id": "KWH6I_QC-cqR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DyqOKIID8jUA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}