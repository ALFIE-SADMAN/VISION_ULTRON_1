{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_xHqE173acg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldY0TDpP4Bw_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b43c78e"
      },
      "source": [
        "1. Environment Setup — Colab Mount, Paths, Assertions, Self-Test\n",
        "2. Imports, Reproducibility, Device Selection, Self-Check\n",
        "3. Training Shards — Discovery, Local Staging, Concatenation, Normalization Wrapper\n",
        "4. FER2013 CSV Splits — Validation/Test Datasets with Consistent Preprocessing\n",
        "5. DataLoaders and Optional Visualization Hook\n",
        "6. Metrics — Accuracy, Class Weights, and Composite Losses (Label Smoothing + Focal)\n",
        "7. MixUp and CutMix Utilities (+ Mixed-Criterion Wrapper)\n",
        "8. EMA (Weights) — Backup/Restore and Safety Checks\n",
        "9. Base Training/Evaluation Mixin (training_step/validation_step/aggregation)\n",
        "10. Training Hyperparameters and Global Knobs\n",
        "11. Model Definition — EfficientNet-B0 + CBAM + optional Sobel\n",
        "12. Optimizer & Scheduler (Warmup-Cosine) & EarlyStopping\n",
        "13. Training Loop — AMP, EMA, MixUp/CutMix, Save-Best Checkpoint\n",
        "14. Launch Training — Build Optimizer/Scheduler/EMA and Fit\n",
        "15. Evaluation Utilities — Base / EMA / EMA + TTA\n",
        "16. Run Evaluation — Validation and Test (Base, EMA, EMA+TTA)\n",
        "17. FLOPs Measurement (fvcore) for 96×96\n",
        "18. Efficiency Summary — Map Metrics, Select Best, Compute Accuracy/GFLOPs\n",
        "19. Save Final Checkpoint — Best Weights + Timestamped Copy\n",
        "20. Reload Checkpoint for Inference — Sanity Forward Pass\n",
        "21. FLOPs Calculation (fvcore) — Standalone Report Cell\n",
        "22. Efficiency Report Preparation — Name Mapping & Best Selection\n",
        "23. Efficiency Function — Accuracy(%) per GFLOP Utility\n",
        "24. Run Efficiency Report — Compute and Print Efficiency Score\n",
        "25. Save Final Checkpoint — Stage C/Final Model Artifact\n",
        "26. Wrap-Up — Final Metrics Summary and Completion Banner\n",
        "27. Stage A (AffectNet) — RGB, ImageNet Normalization, Training\n",
        "28. Stage A Save — Write AffectNet Checkpoint\n",
        "29. Stage B (RAF-DB) — Load Stage A, Fine-Tune on RAF-DB\n",
        "30. Stage B Save — Write RAF-DB Checkpoint\n",
        "31. Stage C (FER2013) — Load Stage B, Final Fine-Tune on FER2013\n",
        "32. Stage C Save — Write FER2013 Checkpoint (Multi-Stage Complete)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OMZPNU-4fwT"
      },
      "source": [
        "Stage 0 — Boot & Storage Safety\n",
        "\n",
        "Cell 01 — Folder & Storage Debug (Auto-Create + Quota Warning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lod2dmJ5CAOk",
        "outputId": "bebe60b2-9ea1-4d8b-8dac-89502458dff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stage0] Disk @ /content/project — total=112.64 GB, used=38.79 GB, free=73.84 GB\n"
          ]
        }
      ],
      "source": [
        "# Creates core directories locally and prints disk quota.\n",
        "\n",
        "import os, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_NAME  = \"facial_expression_recognition_2025\"\n",
        "PROJECT_ROOT  = Path(\"./project\")\n",
        "DATA_ROOT     = Path(\"./data\")\n",
        "CKPT_DIR      = PROJECT_ROOT / \"checkpoints\"\n",
        "LOG_DIR       = PROJECT_ROOT / \"logs\"\n",
        "MIN_FREE_GB   = 2.0  # warn if below this free space\n",
        "\n",
        "for p in [PROJECT_ROOT, DATA_ROOT, CKPT_DIR, LOG_DIR]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "usage = shutil.disk_usage(str(PROJECT_ROOT))\n",
        "free_gb = usage.free / (1024**3)\n",
        "print(f\"[Stage0] Disk @ {PROJECT_ROOT.resolve()} — total={usage.total/(1024**3):.2f} GB, \"\n",
        "      f\"used={usage.used/(1024**3):.2f} GB, free={free_gb:.2f} GB\")\n",
        "if free_gb < MIN_FREE_GB:\n",
        "    print(f\"[Stage0][WARN] Low free space (< {MIN_FREE_GB:.1f} GB). Consider cleaning Drive.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md70Tsg_M0Uj"
      },
      "source": [
        "#Cell 02 — Environment Setup (Colab Mount, Paths, Assertions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "_-CPW6ggM3uc",
        "outputId": "8a568d6a-7a00-484c-fc03-e6b9456638a3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-50697998.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0min_colab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[Stage0] Google Drive mounted.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "# Mounts Drive in Colab and resolves the FER2013 CSV path based on your screenshot.\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "def in_colab() -> bool:\n",
        "    return \"google.colab\" in sys.modules\n",
        "\n",
        "if in_colab():\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\", force_remount=False)\n",
        "    print(\"[Stage0] Google Drive mounted.\")\n",
        "\n",
        "# Your file is in My Drive root:\n",
        "FER_CSV_PATH = Path(\"/content/drive/MyDrive/fer2013.csv\")\n",
        "print(f\"[Stage0] FER CSV: {FER_CSV_PATH if FER_CSV_PATH.exists() else 'NOT FOUND'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmnEFvxuM-OZ"
      },
      "source": [
        "#Cell 03 — Global Switches & Run Config (Single Source of Truth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXqcOpdrNBci"
      },
      "outputs": [],
      "source": [
        "# --- CONFIG (single source of truth) — UPDATED ---\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure FER CSV path points to your Drive root\n",
        "FER_CSV_PATH = Path(\"/content/drive/MyDrive/fer2013.csv\")\n",
        "\n",
        "CONFIG = {\n",
        "    # === Feature toggles ===\n",
        "    \"USE_AUG\": True,          # enable training-time augmentation\n",
        "    \"USE_AUG_ADV\": True,      # advanced FER policy (AugMixLite + occlusion/elastic etc.)\n",
        "    \"AUG_ALPHA\": 0.65,        # blend coefficient for AugMixLite\n",
        "    \"USE_MIXUP\": True,\n",
        "    \"USE_CUTMIX\": True,\n",
        "    \"USE_EMA\": True,\n",
        "    \"USE_TTA\": False,         # keep Val clean; enable TTA only for Test in Cell 27\n",
        "\n",
        "    # === Late-phase controls ===\n",
        "    \"AUG_CAP_LATE\": True,     # cap augmentation strength in the last ~30% epochs\n",
        "    \"TAPER_MIX_LATE\": True,   # taper MixUp/CutMix late\n",
        "\n",
        "    # === Run routing ===\n",
        "    \"RUN_FER\": True,\n",
        "    \"RUN_STAGE_A\": False,\n",
        "    \"RUN_STAGE_B\": False,\n",
        "    \"RUN_STAGE_C\": False,\n",
        "    \"RUN_ALL\": False,\n",
        "    \"DRY_RUN\": False,\n",
        "\n",
        "    # === Dataloading & reproducibility (throughput tuned for Colab 83GB/40GB) ===\n",
        "    \"SEED\": 42,\n",
        "    \"NUM_WORKERS\": 6,         # try 6; if GPU still starves, try 8. If RAM spikes, drop to 4.\n",
        "    \"BATCH_SIZE\": 192,        # safe at 96x96 with 40GB GPU; if OOM, use 176/160/128\n",
        "    \"IMG_SIZE\": 96,\n",
        "\n",
        "    # === Paths ===\n",
        "    \"PROJECT_ROOT\": PROJECT_ROOT,\n",
        "    \"DATA_ROOT\": DATA_ROOT,\n",
        "    \"CKPT_DIR\": CKPT_DIR,\n",
        "    \"LOG_DIR\": LOG_DIR,\n",
        "    \"SAVE_BEST_PATH\": CKPT_DIR / \"best_fer.pth\",\n",
        "    \"FER_CSV_PATH\": FER_CSV_PATH,\n",
        "}\n",
        "\n",
        "# Nice, aligned snapshot\n",
        "print(\"[Stage0] CONFIG snapshot:\")\n",
        "for k in sorted(CONFIG.keys()):\n",
        "    print(f\"  - {k:16s}: {CONFIG[k]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfXgWu_NNDYj"
      },
      "source": [
        "#Cell 04 — Imports, Versions, Reproducibility, Device Self-Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JwHVOA2NGPf"
      },
      "outputs": [],
      "source": [
        "import math, random, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as VF\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "print(f\"[Stage0] torch={torch.__version__}, torchvision={torchvision.__version__}, numpy={np.__version__}\")\n",
        "\n",
        "SEED = int(CONFIG[\"SEED\"])\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    dev_id = torch.cuda.current_device()\n",
        "    props = torch.cuda.get_device_properties(dev_id)\n",
        "    print(f\"[Stage0] CUDA:{dev_id} — {props.name} — {props.total_memory/(1024**3):.1f} GB VRAM\")\n",
        "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
        "    print(\"[Stage0] Device: Apple MPS\")\n",
        "else:\n",
        "    print(\"[Stage0] Device: CPU\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KDrvY2HNaqo"
      },
      "source": [
        "#Cell 05 — Training Shards: Discovery & Local Staging (No Normalize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPN-6d-CNddO"
      },
      "outputs": [],
      "source": [
        "# Optional shard discovery; safe no-op if you do not pre-generate shards.\n",
        "\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "SHARDS_ROOT = CONFIG[\"DATA_ROOT\"] / \"augmented_data\"\n",
        "LOCAL_STAGE = CONFIG[\"DATA_ROOT\"] / \"_local_stage\"\n",
        "LOCAL_STAGE.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if SHARDS_ROOT.exists():\n",
        "    shards = sorted([p for p in SHARDS_ROOT.rglob(\"*.pt\")])\n",
        "    print(f\"[Stage0] Found {len(shards)} shards under {SHARDS_ROOT}\")\n",
        "    if len(shards) > 0:\n",
        "        sample_dst = LOCAL_STAGE / shards[0].name\n",
        "        if not sample_dst.exists():\n",
        "            try:\n",
        "                shutil.copy2(shards[0], sample_dst)\n",
        "                print(f\"[Stage0] Staged sample shard → {sample_dst}\")\n",
        "            except Exception as e:\n",
        "                print(f\"[Stage0][WARN] Could not stage shard: {e}\")\n",
        "else:\n",
        "    print(\"[Stage0] No shards directory present (this is fine).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDnnfo0SNfpD"
      },
      "source": [
        "#Cell 06 — FER2013 CSV Parse & Split (Robust)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zp2aJVzFNhaB"
      },
      "outputs": [],
      "source": [
        "# Loads FER2013 from the fixed path and makes train/val/test DataFrames.\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "assert CONFIG[\"RUN_FER\"], \"RUN_FER=False; skip if not using FER2013.\"\n",
        "assert CONFIG[\"FER_CSV_PATH\"] is not None and Path(CONFIG[\"FER_CSV_PATH\"]).exists(), \\\n",
        "    \"FER2013 CSV not found at /content/drive/MyDrive/fer2013.csv\"\n",
        "\n",
        "fer_df = pd.read_csv(CONFIG[\"FER_CSV_PATH\"])\n",
        "expected_cols = {\"emotion\", \"pixels\"}\n",
        "assert expected_cols.issubset({c.lower() for c in fer_df.columns}), \\\n",
        "    f\"FER CSV missing required columns {expected_cols}. Found: {fer_df.columns.tolist()}\"\n",
        "\n",
        "if \"Usage\" in fer_df.columns:\n",
        "    tr_df = fer_df[fer_df[\"Usage\"] == \"Training\"].reset_index(drop=True)\n",
        "    va_df = fer_df[fer_df[\"Usage\"] == \"PublicTest\"].reset_index(drop=True)\n",
        "    te_df = fer_df[fer_df[\"Usage\"] == \"PrivateTest\"].reset_index(drop=True)\n",
        "else:\n",
        "    perm = np.random.permutation(len(fer_df))\n",
        "    n = len(fer_df); n_tr = int(0.8*n); n_va = int(0.1*n)\n",
        "    idx_tr, idx_va = perm[:n_tr], perm[n_tr:n_tr+n_va]\n",
        "    mask = np.zeros(n, dtype=bool); mask[idx_tr]=True; mask[idx_va]=True\n",
        "    tr_df = fer_df.iloc[idx_tr].reset_index(drop=True)\n",
        "    va_df = fer_df.iloc[idx_va].reset_index(drop=True)\n",
        "    te_df = fer_df.loc[~mask].reset_index(drop=True)\n",
        "\n",
        "print(f\"[Stage0] FER splits — train={len(tr_df)}, val={len(va_df)}, test={len(te_df)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpSeNJeZNjCn"
      },
      "source": [
        "#Cell 07 — Dataset Definition (48×48 → 96×96, No Normalize Yet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhid26vXNmQK"
      },
      "outputs": [],
      "source": [
        "# CSV-backed dataset converting space-separated pixels → [1,H,W] float tensor.\n",
        "# Resize to 96×96 here; normalization is applied later (in aug or eval transform).\n",
        "\n",
        "class FER2013Dataset(Dataset):\n",
        "    def __init__(self, df, img_size=96):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_size = int(img_size)\n",
        "        if len(self.df) > 0:\n",
        "            _ = self._row_to_tensor(0)\n",
        "\n",
        "    def _row_to_tensor(self, idx: int) -> torch.Tensor:\n",
        "        px = self.df.iloc[idx][\"pixels\"]\n",
        "        arr = np.fromstring(str(px), sep=\" \", dtype=np.float32)\n",
        "        assert arr.size == 48*48, f\"Row {idx}: expected 2304 pixels, got {arr.size}\"\n",
        "        img = torch.from_numpy(arr.reshape(48, 48)).unsqueeze(0)  # [1,48,48]\n",
        "        img = VF.resize(img, [self.img_size, self.img_size],\n",
        "                        interpolation=torchvision.transforms.InterpolationMode.BILINEAR,\n",
        "                        antialias=True)\n",
        "        return img  # still [0..255]\n",
        "\n",
        "    def __len__(self): return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self._row_to_tensor(idx)\n",
        "        y = int(self.df.iloc[idx][\"emotion\"])\n",
        "        return x, y\n",
        "\n",
        "IMG_SIZE = int(CONFIG[\"IMG_SIZE\"])\n",
        "train_ds = FER2013Dataset(tr_df, img_size=IMG_SIZE)\n",
        "valid_ds = FER2013Dataset(va_df, img_size=IMG_SIZE)\n",
        "test_ds  = FER2013Dataset(te_df, img_size=IMG_SIZE)\n",
        "print(\"[Stage0] Dataset objects built.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXSE5ctVNn0G"
      },
      "source": [
        "#Cell 08 — DataLoaders (No Aug Yet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ka5VEPz2Nr0-"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE  = int(CONFIG[\"BATCH_SIZE\"])\n",
        "NUM_WORKERS = int(CONFIG[\"NUM_WORKERS\"])\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                      num_workers=NUM_WORKERS, pin_memory=True,\n",
        "                      persistent_workers=(NUM_WORKERS>0))\n",
        "valid_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE*2, shuffle=False,\n",
        "                      num_workers=NUM_WORKERS, pin_memory=True,\n",
        "                      persistent_workers=(NUM_WORKERS>0))\n",
        "test_dl  = DataLoader(test_ds,  batch_size=BATCH_SIZE*2, shuffle=False,\n",
        "                      num_workers=NUM_WORKERS, pin_memory=True,\n",
        "                      persistent_workers=(NUM_WORKERS>0))\n",
        "\n",
        "xb, yb = next(iter(train_dl))\n",
        "print(f\"[Stage0] Train batch shape: {xb.shape}, {yb.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzRNS4RMOiay"
      },
      "source": [
        "#Cell 09 — Optional Visualization Hook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HU_AbnxTOkKG"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid\n",
        "\n",
        "def show_batch(dl, nrow=16, title='Raw FER2013 batch (resized)'):\n",
        "    imgs, labels = next(iter(dl))\n",
        "    grid = make_grid(imgs[:nrow], nrow=nrow)\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.axis('off'); plt.title(title)\n",
        "    plt.imshow(grid.permute(1,2,0).squeeze(), cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "# Uncomment to preview\n",
        "#show_batch(train_dl)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRvueO8vOvFy"
      },
      "source": [
        "#Cell 10 — Augmentation Primitives (Grayscale-Friendly)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTNv_xLoOxIF"
      },
      "outputs": [],
      "source": [
        "# ===== Advanced grayscale operators (tensor I/O) =====\n",
        "# INPUT  : x in [C=1,H,W], values in [0,255]\n",
        "# OUTPUT : same shape/range unless otherwise noted\n",
        "\n",
        "import math, random\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as VF\n",
        "from PIL import Image, ImageFilter, ImageOps\n",
        "import io\n",
        "\n",
        "# ---- Small utilities ----\n",
        "def _to_pil_gray(x255: torch.Tensor) -> Image.Image:\n",
        "    # [1,H,W] -> PIL 'L'\n",
        "    x = x255.clamp(0, 255).to(torch.uint8).squeeze(0).cpu().numpy()\n",
        "    return Image.fromarray(x, mode='L')\n",
        "\n",
        "def _from_pil_gray(img: Image.Image) -> torch.Tensor:\n",
        "    # PIL 'L' -> [1,H,W] float32 in [0,255]\n",
        "    return torch.tensor(np.array(img, dtype=np.uint8), dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "def _clamp255(x): return x.clamp(0.0, 255.0)\n",
        "\n",
        "# ---- Photometric / intensity ----\n",
        "def gauss_noise(x, sigma=0.02):\n",
        "    n = torch.randn_like(x) * (sigma * 255.0)\n",
        "    return _clamp255(x + n)\n",
        "\n",
        "def rand_gamma(x, gmin=0.8, gmax=1.25):\n",
        "    g = random.uniform(gmin, gmax)\n",
        "    x01 = (x / 255.0).clamp(0,1)\n",
        "    return (x01.pow(g) * 255.0)\n",
        "\n",
        "def rand_contrast(x, scale=0.25):\n",
        "    c = 1.0 + random.uniform(-scale, scale)\n",
        "    mean = x.mean(dim=(1,2), keepdim=True)\n",
        "    return _clamp255((x - mean) * c + mean)\n",
        "\n",
        "def rand_equalize(x):\n",
        "    img = _to_pil_gray(x); img = ImageOps.equalize(img)\n",
        "    return _from_pil_gray(img).to(x.dtype).to(x.device)\n",
        "\n",
        "def rand_jpeg(x, qmin=45, qmax=85):\n",
        "    img = _to_pil_gray(x)\n",
        "    buf = io.BytesIO()\n",
        "    img.save(buf, format='JPEG', quality=random.randint(qmin, qmax))\n",
        "    buf.seek(0)\n",
        "    img2 = Image.open(buf).convert('L')\n",
        "    return _from_pil_gray(img2).to(x.dtype).to(x.device)\n",
        "\n",
        "def rand_vignette(x, strength=0.25):\n",
        "    _, H, W = x.shape\n",
        "    yy, xx = torch.meshgrid(torch.linspace(-1,1,H,device=x.device),\n",
        "                            torch.linspace(-1,1,W,device=x.device), indexing='ij')\n",
        "    r = torch.sqrt(xx**2 + yy**2)\n",
        "    mask = 1.0 - strength * (r / r.max()).clamp(0,1)\n",
        "    return _clamp255(x * mask.unsqueeze(0))\n",
        "\n",
        "def rand_blur(x, k=3):\n",
        "    return VF.gaussian_blur(x, kernel_size=k)\n",
        "\n",
        "# ---- Geometric ----\n",
        "def rand_affine_small(x, max_rot=12.0, max_trans=0.08, max_shear=8.0, max_scale=0.08):\n",
        "    H, W = x.shape[-2:]\n",
        "    angle = random.uniform(-max_rot, max_rot)\n",
        "    trans = [int(random.uniform(-max_trans, max_trans) * W),\n",
        "             int(random.uniform(-max_trans, max_trans) * H)]\n",
        "    scale = 1.0 + random.uniform(-max_scale, max_scale)\n",
        "    shear = [random.uniform(-max_shear, max_shear), 0.0]\n",
        "    return VF.affine(x, angle=angle, translate=trans, scale=scale, shear=shear)\n",
        "\n",
        "def rand_pad_crop(x, pad=3):\n",
        "    # pad then random crop back to original size\n",
        "    _, H, W = x.shape\n",
        "    xpad = F.pad(x, (pad, pad, pad, pad), mode='reflect')\n",
        "    i = random.randint(0, 2*pad); j = random.randint(0, 2*pad)\n",
        "    return xpad[:, i:i+H, j:j+W]\n",
        "\n",
        "def rand_hflip(x, p=0.5):\n",
        "    return VF.hflip(x) if random.random() < p else x\n",
        "\n",
        "# Elastic deformation: small, smoothed displacement field\n",
        "def rand_elastic(x, alpha=1.0, sigma=4.0):\n",
        "    _, H, W = x.shape\n",
        "    # displacement fields\n",
        "    dx = torch.randn(1,1,H,W, device=x.device)\n",
        "    dy = torch.randn(1,1,H,W, device=x.device)\n",
        "    # smooth them by Gaussian\n",
        "    def _gauss_kernel(k=21, s=sigma):\n",
        "        ax = torch.arange(k, device=x.device) - (k-1)/2\n",
        "        ker = torch.exp(-(ax**2)/(2*s*s)); ker = ker/ker.sum()\n",
        "        return ker\n",
        "    k = 21\n",
        "    gx = _gauss_kernel(k).view(1,1,1,k)\n",
        "    gy = _gauss_kernel(k).view(1,1,k,1)\n",
        "    dx = F.conv2d(dx, gx, padding=(0,k//2)); dx = F.conv2d(dx, gy, padding=(k//2,0))\n",
        "    dy = F.conv2d(dy, gx, padding=(0,k//2)); dy = F.conv2d(dy, gy, padding=(k//2,0))\n",
        "    dx = dx.squeeze(0).squeeze(0) * alpha\n",
        "    dy = dy.squeeze(0).squeeze(0) * alpha\n",
        "\n",
        "    # grid in [-1,1]\n",
        "    yy, xx = torch.meshgrid(torch.linspace(-1,1,H,device=x.device),\n",
        "                            torch.linspace(-1,1,W,device=x.device), indexing='ij')\n",
        "    xx = (xx + dx / (W/2)).clamp(-1,1)\n",
        "    yy = (yy + dy / (H/2)).clamp(-1,1)\n",
        "    grid = torch.stack([xx, yy], dim=-1).unsqueeze(0)  # [1,H,W,2]\n",
        "    return F.grid_sample(x.unsqueeze(0), grid, mode='bilinear', padding_mode='border', align_corners=True).squeeze(0)\n",
        "\n",
        "# ---- Occlusion (domain-specific) ----\n",
        "def band_occlusion(x, mode='eyes', frac=0.18):\n",
        "    _, H, W = x.shape\n",
        "    band_h = max(1, int(frac*H))\n",
        "    y0 = {\n",
        "        'eyes': int(0.35*H) - band_h//2,\n",
        "        'mouth': int(0.75*H) - band_h//2,\n",
        "        'top': int(0.15*H) - band_h//2\n",
        "    }[mode]\n",
        "    y1 = max(0, y0); y2 = min(H, y0 + band_h)\n",
        "    x = x.clone()\n",
        "    x[:, y1:y2, :] = x[:, y1:y2, :].mean()  # neutral occluder (gray)\n",
        "    return x\n",
        "\n",
        "def localized_erasing(x, min_frac=0.01, max_frac=0.05):\n",
        "    C, H, W = x.shape\n",
        "    area = random.uniform(min_frac, max_frac) * H * W\n",
        "    side = int(max(2, math.sqrt(area)))\n",
        "    cx, cy = random.randint(0,W-1), random.randint(0,H-1)\n",
        "    x[:, max(0,cy-side//2):min(H,cy+side//2), max(0,cx-side//2):min(W,cx+side//2)] = 127.5\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3wTzPMWOygO"
      },
      "source": [
        "#Cell 11 — Augmentation Pipeline Builder (Curriculum; Output Normalized [-1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxNGpw7nO1MI"
      },
      "outputs": [],
      "source": [
        "# ===== AugMixLite: blend multiple sub-policies with the original =====\n",
        "def _apply_bank(x, bank, k=2):\n",
        "    y = x.clone()\n",
        "    for _ in range(k):\n",
        "        op = random.choice(bank)\n",
        "        y = op(y)\n",
        "    return y\n",
        "\n",
        "def augmix_lite(x, banks, alpha=0.65, branches=2, depth=2):\n",
        "    mix = x.clone()\n",
        "    for _ in range(branches):\n",
        "        b = random.choice(banks)\n",
        "        y = _apply_bank(x, b, k=depth)\n",
        "        mix = mix + y\n",
        "    mix = mix / (branches + 1.0)\n",
        "    return (1 - alpha) * x + alpha * mix\n",
        "\n",
        "# ===== Advanced augmentation builder =====\n",
        "def build_advanced_fer_augment(strength: float):\n",
        "    \"\"\"\n",
        "    strength s in [0,1]: controls probabilities/magnitudes.\n",
        "    Returns f(x255->[1,H,W]) -> x_norm in [-1,1].\n",
        "    \"\"\"\n",
        "    s = float(max(0.0, min(1.0, strength)))\n",
        "    # Probabilities\n",
        "    p_photo = 0.7 * (0.5 + 0.5*s)\n",
        "    p_geom  = 0.6 * (0.5 + 0.5*s)\n",
        "    p_occl  = 0.40 * (0.5 + 0.5*s)\n",
        "    p_equal = 0.20 * s\n",
        "    p_blur  = 0.15 * s\n",
        "    # Magnitudes\n",
        "    gamma_rng = (0.85 - 0.15*s, 1.20 + 0.05*s)\n",
        "    contrast_scale = 0.20 + 0.10*s\n",
        "    jpeg_q = (55 - int(10*s), 85)\n",
        "    vignette_str = 0.15 + 0.20*s\n",
        "    elastic_alpha = 0.6 + 0.8*s\n",
        "    rot = 10 + 5*s\n",
        "    shear = 6 + 4*s\n",
        "    trans = 0.06 + 0.03*s\n",
        "    scale = 0.06 + 0.04*s\n",
        "\n",
        "    # Banks\n",
        "    photometric_bank = [\n",
        "        lambda z: gauss_noise(z, sigma=0.015 + 0.02*s),\n",
        "        lambda z: rand_gamma(z, *gamma_rng),\n",
        "        lambda z: rand_contrast(z, scale=contrast_scale),\n",
        "        lambda z: rand_jpeg(z, qmin=jpeg_q[0], qmax=jpeg_q[1]),\n",
        "        lambda z: rand_vignette(z, strength=vignette_str),\n",
        "    ]\n",
        "    geometric_bank = [\n",
        "        lambda z: rand_affine_small(z, max_rot=rot, max_trans=trans, max_shear=shear, max_scale=scale),\n",
        "        lambda z: rand_pad_crop(z, pad=3),\n",
        "        lambda z: rand_hflip(z, p=0.5),\n",
        "        lambda z: rand_elastic(z, alpha=elastic_alpha, sigma=4.0),\n",
        "    ]\n",
        "    occlusion_bank = [\n",
        "        lambda z: band_occlusion(z, mode='eyes',  frac=0.16 + 0.06*s),\n",
        "        lambda z: band_occlusion(z, mode='mouth', frac=0.16 + 0.06*s),\n",
        "        lambda z: band_occlusion(z, mode='top',   frac=0.14 + 0.06*s),\n",
        "        lambda z: localized_erasing(z, min_frac=0.01, max_frac=0.05),\n",
        "    ]\n",
        "    banks = [photometric_bank, geometric_bank, occlusion_bank]\n",
        "\n",
        "    def _norm_to_m11(x255):\n",
        "        x01 = (x255 / 255.0).clamp(0,1)\n",
        "        return (x01 - 0.5) * 2.0\n",
        "\n",
        "    def _augment(x):\n",
        "        # 1) pre-crop/pad + optional blur\n",
        "        if random.random() < p_geom:  x = rand_pad_crop(x, pad=3)\n",
        "        if random.random() < p_blur:  x = rand_blur(x, k=3)\n",
        "\n",
        "        # 2) photometric block\n",
        "        if random.random() < p_photo: x = random.choice(photometric_bank)(x)\n",
        "\n",
        "        # 3) AugMixLite composite (2 branches × depth=2)\n",
        "        x = augmix_lite(x, banks=banks, alpha=CONFIG.get(\"AUG_ALPHA\", 0.65),\n",
        "                        branches=2, depth=2)\n",
        "\n",
        "        # 4) more geometric and occlusion chance\n",
        "        if random.random() < p_geom:  x = random.choice(geometric_bank)(x)\n",
        "        if random.random() < p_occl:  x = random.choice(occlusion_bank)(x)\n",
        "\n",
        "        # 5) occasional histogram equalization near the end\n",
        "        if random.random() < p_equal: x = rand_equalize(x)\n",
        "\n",
        "        # Normalize to [-1,1] for the model\n",
        "        return _norm_to_m11(x)\n",
        "\n",
        "    return _augment\n",
        "\n",
        "# Keep legacy factory for fallback\n",
        "FER_AUG_FACTORY = build_advanced_fer_augment if CONFIG.get(\"USE_AUG_ADV\", False) else build_fer_augment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gQFbYZsO3nL"
      },
      "source": [
        "#Cell 12 — Augmentation Debug Cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XEOf68KO5Sp"
      },
      "outputs": [],
      "source": [
        "if CONFIG[\"USE_AUG\"]:\n",
        "    xs, ys = next(iter(train_dl))\n",
        "    xs = xs[:8].to('cpu')\n",
        "    for s in [0.0, 0.5, 1.0]:\n",
        "        f = FER_AUG_FACTORY(s)\n",
        "        x_aug = torch.stack([f(x) for x in xs])  # [-1,1]\n",
        "        assert x_aug.shape == xs.shape and torch.isfinite(x_aug).all()\n",
        "        print(f\"[AugDebug] s={s}: min={x_aug.min().item():.3f}, max={x_aug.max().item():.3f}\")\n",
        "        # Optional quick glance\n",
        "        # grid = (x_aug * 0.5 + 0.5).clamp(0,1)\n",
        "        # grid = make_grid(grid, nrow=8)\n",
        "        # plt.figure(figsize=(12,3)); plt.axis('off'); plt.title(f'Advanced Aug s={s}')\n",
        "        # plt.imshow(grid.permute(1,2,0).squeeze(), cmap='gray'); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4ZRABSbO7ip"
      },
      "source": [
        "#Cell 13 — Metrics: Accuracy & Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0cCKIM2O-El"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def accuracy(logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
        "    return (logits.argmax(dim=1) == targets).float().mean()\n",
        "\n",
        "def compute_class_weights(df) -> torch.Tensor:\n",
        "    counts = Counter(int(e) for e in df[\"emotion\"].tolist())\n",
        "    total = sum(counts.values())\n",
        "    weights = [total / max(1, counts.get(c, 1)) for c in range(7)]\n",
        "    w = torch.tensor(weights, dtype=torch.float32)\n",
        "    return w / w.mean()\n",
        "\n",
        "CLASS_WEIGHTS = compute_class_weights(tr_df)\n",
        "print(f\"[Stage1] Class weights: {CLASS_WEIGHTS.tolist()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFH8-w0iPAra"
      },
      "source": [
        "#Cell 14 — Losses: Label-Smoothed CE, Focal, Composite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bD7TSaSDPCpd"
      },
      "outputs": [],
      "source": [
        "# Replace your CompositeLoss with this “SmoothedFocal” preset.\n",
        "class LabelSmoothingCE(nn.Module):\n",
        "    def __init__(self, eps=0.10, reduction='mean'):\n",
        "        super().__init__(); self.eps=eps; self.reduction=reduction\n",
        "    def forward(self, logits, targets):\n",
        "        n = logits.size(-1)\n",
        "        logp = F.log_softmax(logits, dim=-1)\n",
        "        with torch.no_grad():\n",
        "            true = torch.zeros_like(logp).fill_(self.eps/(n-1))\n",
        "            true.scatter_(1, targets.unsqueeze(1), 1.0 - self.eps)\n",
        "        loss = -(true * logp).sum(dim=1)\n",
        "        return loss.mean() if self.reduction=='mean' else loss\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=1.5, reduction='mean'):\n",
        "        super().__init__(); self.g=gamma; self.reduction=reduction\n",
        "    def forward(self, logits, targets):\n",
        "        ce = F.cross_entropy(logits, targets, reduction='none')\n",
        "        pt = torch.exp(-ce)\n",
        "        fl = ((1-pt)**self.g) * ce\n",
        "        return fl.mean() if self.reduction=='mean' else fl\n",
        "\n",
        "class SmoothedFocal(nn.Module):\n",
        "    def __init__(self, eps=0.10, gamma=1.5, alpha=0.70, weight=None):\n",
        "        super().__init__(); self.a=alpha; self.w = weight\n",
        "        self.lsce = LabelSmoothingCE(eps)\n",
        "        self.focal= FocalLoss(gamma)\n",
        "    def forward(self, logits, targets):\n",
        "        if self.w is not None:\n",
        "            # weight affects CE inside focal; apply by hand\n",
        "            ce = F.cross_entropy(logits, targets, reduction='none', weight=self.w.to(logits.device))\n",
        "            pt = torch.exp(-ce); fl = ((1-pt)**1.5) * ce\n",
        "            ls = self.lsce(logits, targets)\n",
        "            return self.a*ls + (1-self.a)*fl.mean()\n",
        "        return self.a*self.lsce(logits, targets) + (1-self.a)*self.focal(logits, targets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZvGD2yRPD-B"
      },
      "source": [
        "#Cell 15 — MixUp & CutMix Utilities + Mixed Criterion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_GdzW7CPG1_"
      },
      "outputs": [],
      "source": [
        "def mixup_data(x, y, alpha=0.2):\n",
        "    if alpha <= 0.0:\n",
        "        return x, y, 1.0, None\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    index = torch.randperm(x.size(0), device=x.device)\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, (y_a, y_b), lam, index\n",
        "\n",
        "def cutmix_data(x, y, alpha=1.0, min_lam=0.3, max_lam=0.7):\n",
        "    if alpha <= 0.0:\n",
        "        return x, y, 1.0, None\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    lam = float(max(min_lam, min(max_lam, lam)))\n",
        "    B, C, H, W = x.size()\n",
        "    index = torch.randperm(B, device=x.device)\n",
        "    cut_w = int(W * math.sqrt(1 - lam))\n",
        "    cut_h = int(H * math.sqrt(1 - lam))\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "    x1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    x2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    y1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    y2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "    x[:, :, y1:y2, x1:x2] = x[index, :, y1:y2, x1:x2]\n",
        "    lam = 1 - ((x2 - x1) * (y2 - y1) / (W * H + 1e-9))\n",
        "    y_a, y_b = y, y[index]\n",
        "    return x, (y_a, y_b), lam, index\n",
        "\n",
        "def mixed_criterion(criterion, logits, targets_mix, lam):\n",
        "    if isinstance(targets_mix, tuple):\n",
        "        y_a, y_b = targets_mix\n",
        "        return lam * criterion(logits, y_a) + (1 - lam) * criterion(logits, y_b)\n",
        "    else:\n",
        "        return criterion(logits, targets_mix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikjEOYF6PMce"
      },
      "source": [
        "#Cell 16 — EMA (Exponential Moving Average) for Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aux44u9ePPhv"
      },
      "outputs": [],
      "source": [
        "class EMA:\n",
        "    def __init__(self, model: nn.Module, decay: float = 0.999):\n",
        "        self.decay = float(decay)\n",
        "        self.shadow = {}\n",
        "        self.backup = {}\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                self.shadow[name] = param.data.clone()\n",
        "\n",
        "    def update(self, model: nn.Module):\n",
        "        for name, param in model.named_parameters():\n",
        "            if not param.requires_grad:\n",
        "                continue\n",
        "            self.shadow[name] = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]\n",
        "\n",
        "    def apply_shadow(self, model: nn.Module):\n",
        "        self.backup = {}\n",
        "        for name, param in model.named_parameters():\n",
        "            if not param.requires_grad:\n",
        "                continue\n",
        "            self.backup[name] = param.data.clone()\n",
        "            param.data = self.shadow[name].clone()\n",
        "\n",
        "    def restore(self, model: nn.Module):\n",
        "        for name, param in model.named_parameters():\n",
        "            if not param.requires_grad:\n",
        "                continue\n",
        "            param.data = self.backup[name].clone()\n",
        "        self.backup = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jrmj1e_PQwd"
      },
      "source": [
        "#Cell 17 — Base Training/Evaluation Mixin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nknmYGNnPTGM"
      },
      "outputs": [],
      "source": [
        "class TrainingMixin:\n",
        "    def training_step(self, batch, criterion):\n",
        "        x, y = batch\n",
        "        x, y = x.to(self.device), y.to(self.device)\n",
        "        logits = self(x)\n",
        "        loss = criterion(logits, y)\n",
        "        return loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def validation_step(self, batch, criterion):\n",
        "        x, y = batch\n",
        "        x, y = x.to(self.device), y.to(self.device)\n",
        "        logits = self(x)\n",
        "        loss = criterion(logits, y)\n",
        "        acc = accuracy(logits, y)\n",
        "        return loss.detach(), acc.detach()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def evaluate_loader(self, loader, criterion):\n",
        "        self.eval()\n",
        "        losses, accs = [], []\n",
        "        for batch in loader:\n",
        "            l, a = self.validation_step(batch, criterion)\n",
        "            losses.append(l.item()); accs.append(a.item())\n",
        "        return float(np.mean(losses)), float(np.mean(accs))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ymRPHafPUZs"
      },
      "source": [
        "#Cell 18 — Training Hyperparameters & Global Knobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oUfKVzEPW9Z"
      },
      "outputs": [],
      "source": [
        "HP = {\n",
        "    \"EPOCHS\": 50,\n",
        "    \"LR\": 3e-4,\n",
        "    \"WD\": 1e-4,\n",
        "    \"WARMUP_EPOCHS\": 4,\n",
        "    \"LR_MIN\": 1e-6,\n",
        "    \"PATIENCE\": 8,\n",
        "    \"EMA_DECAY\": 0.999,\n",
        "    \"MIXUP_ALPHA\": 0.3,\n",
        "    \"CUTMIX_ALPHA\": 1.0,\n",
        "    \"AUG_RAMP_EPOCHS\": 0.3,  # fraction of total epochs for curriculum ramp\n",
        "}\n",
        "print(\"[Stage1] HP snapshot:\", HP)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0E74WzYPYh3"
      },
      "source": [
        "#Cell 19 — CBAM Block (Attention Module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUopqauqPbdt"
      },
      "outputs": [],
      "source": [
        "class CBAM(nn.Module):\n",
        "    def __init__(self, ch, r=8):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Conv2d(ch, max(1, ch//r), 1, bias=True), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(max(1, ch//r), ch, 1, bias=True)\n",
        "        )\n",
        "        self.spatial = nn.Sequential(\n",
        "            nn.Conv2d(2, 1, kernel_size=7, padding=3, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        ca = F.adaptive_avg_pool2d(x, 1) + F.adaptive_max_pool2d(x, 1)\n",
        "        ca = self.sigmoid(self.mlp(ca))\n",
        "        x = x * ca\n",
        "        ms = torch.cat([x.mean(1, keepdim=True), x.max(1, keepdim=True)[0]], dim=1)\n",
        "        sa = self.spatial(ms)\n",
        "        return x * sa\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp3IswFBPcx7"
      },
      "source": [
        "#Cell 20 — Optional Sobel Stem (for Grayscale Edges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6AxJfsjPe89"
      },
      "outputs": [],
      "source": [
        "class SobelStem(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        kernel_x = torch.tensor([[1,0,-1],[2,0,-2],[1,0,-1]], dtype=torch.float32)\n",
        "        kernel_y = torch.tensor([[1,2,1],[0,0,0],[-1,-2,-1]], dtype=torch.float32)\n",
        "        self.register_buffer('kx', kernel_x.view(1,1,3,3))\n",
        "        self.register_buffer('ky', kernel_y.view(1,1,3,3))\n",
        "    def forward(self, x):\n",
        "        gx = F.conv2d(x, self.kx, padding=1)\n",
        "        gy = F.conv2d(x, self.ky, padding=1)\n",
        "        g = torch.sqrt(gx**2 + gy**2 + 1e-6)\n",
        "        return torch.cat([x, g], dim=1)  # [B,2,H,W]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER92xzPAPga2"
      },
      "source": [
        "#Cell 21 — HybridEffNet Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tvrj2UVTPkkw"
      },
      "outputs": [],
      "source": [
        "# ===== Cell 21 — HybridEffNet Model Definition (REPLACE) =====\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "\n",
        "# Pull optional knobs from CONFIG with safe defaults\n",
        "CLASSIFIER_DROPOUT = float(CONFIG.get(\"CLASSIFIER_DROPOUT\", 0.30))\n",
        "USE_CBAM = bool(CONFIG.get(\"USE_CBAM\", True))  # keep True to match prior runs\n",
        "\n",
        "class SobelLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        kx = torch.tensor([[1,0,-1],[2,0,-2],[1,0,-1]], dtype=torch.float32)\n",
        "        ky = torch.tensor([[1,2,1],[0,0,0],[-1,-2,-1]], dtype=torch.float32)\n",
        "        w  = torch.stack([kx, ky]).unsqueeze(1)  # (2,1,3,3)\n",
        "        self.register_buffer('w', w)\n",
        "\n",
        "    def forward(self, x):            # x:[B,1,H,W]\n",
        "        edges = F.conv2d(x, self.w, padding=1)   # [B,2,H,W]\n",
        "        return torch.cat([x, edges], dim=1)      # [B,3,H,W]\n",
        "\n",
        "class HybridEffNet(nn.Module, TrainingMixin):\n",
        "    def __init__(self, num_classes=7, classifier_dropout=CLASSIFIER_DROPOUT, use_cbam=USE_CBAM):\n",
        "        super().__init__()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        base = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
        "\n",
        "        # Sobel expands 1→3 channels so we can keep EfficientNet stem unchanged\n",
        "        self.sobel    = SobelLayer()\n",
        "        self.features = base.features\n",
        "        self.pool     = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # Optional CBAM on the final feature map (requires Cell 19)\n",
        "        self.cbam = CBAM(1280) if use_cbam else None\n",
        "\n",
        "        in_features = 1280  # EfficientNet-B0 penultimate dim\n",
        "        self.bn   = nn.BatchNorm1d(in_features)\n",
        "        self.drop = nn.Dropout(p=classifier_dropout)\n",
        "        self.head = nn.Linear(in_features, num_classes)\n",
        "\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, x1):           # x1 in [-1,1], shape [B,1,H,W]\n",
        "        x3 = self.sobel(x1)          # [B,3,H,W]\n",
        "        f  = self.features(x3)       # [B,1280,h,w]\n",
        "        if self.cbam is not None:\n",
        "            f = self.cbam(f)\n",
        "        f  = self.pool(f).flatten(1) # [B,1280]\n",
        "        f  = self.bn(f)\n",
        "        f  = self.drop(f)\n",
        "        return self.head(f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU_ywDDUPmB4"
      },
      "source": [
        "#Cell 22 — Optimizer, Warmup-Cosine Scheduler, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYHbUtgmPn9I"
      },
      "outputs": [],
      "source": [
        "def make_adamw(params, lr, wd):\n",
        "    return torch.optim.AdamW(params, lr=lr, weight_decay=wd)\n",
        "\n",
        "class WarmupCosine:\n",
        "    def __init__(self, optimizer, warmup_epochs, max_epochs, lr_min=1e-6, lr_max=None):\n",
        "        self.opt = optimizer\n",
        "        self.warmup = max(1, int(warmup_epochs))\n",
        "        self.maxe = int(max_epochs)\n",
        "        self.t = 0\n",
        "        self.lr_min = lr_min\n",
        "        self.lr_max = lr_max if lr_max is not None else max(g['lr'] for g in optimizer.param_groups)\n",
        "    def step(self):\n",
        "        self.t += 1\n",
        "        if self.t <= self.warmup:\n",
        "            lr = self.lr_min + (self.lr_max - self.lr_min) * (self.t / self.warmup)\n",
        "        else:\n",
        "            tt = (self.t - self.warmup) / max(1, (self.maxe - self.warmup))\n",
        "            lr = self.lr_min + 0.5*(self.lr_max - self.lr_min)*(1 + math.cos(math.pi*tt))\n",
        "        for g in self.opt.param_groups:\n",
        "            g['lr'] = lr\n",
        "        return lr\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=8, min_delta=1e-4):\n",
        "        self.patience = int(patience)\n",
        "        self.min_delta = float(min_delta)\n",
        "        self.best = float('inf')\n",
        "        self.bad = 0\n",
        "    def step(self, val_loss):\n",
        "        if val_loss < self.best - self.min_delta:\n",
        "            self.best = val_loss\n",
        "            self.bad = 0\n",
        "            return False\n",
        "        self.bad += 1\n",
        "        return self.bad >= self.patience\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z9WyhD3PpUd"
      },
      "source": [
        "#Cell 23 — fit_with_aug(): Training Loop with Aug/Mix/EMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlOTFD_yPrxa"
      },
      "outputs": [],
      "source": [
        "# === Cell 23 — fit_with_aug(): advanced aug + late-phase taper + AMP + EMA ===\n",
        "def fit_with_aug(model: nn.Module, train_dl, valid_dl, hp, config):\n",
        "    device = model.device\n",
        "\n",
        "    # Loss with class weights (computed earlier)\n",
        "    weight = CLASS_WEIGHTS.to(device)\n",
        "    criterion = SmoothedFocal(eps=0.10, gamma=1.5, alpha=0.70, weight=weight)\n",
        "\n",
        "    # Optimizer / Scheduler / EarlyStop / EMA / AMP\n",
        "    opt   = make_adamw(model.parameters(), lr=hp[\"LR\"], wd=hp[\"WD\"])\n",
        "    sched = WarmupCosine(opt, warmup_epochs=hp[\"WARMUP_EPOCHS\"],\n",
        "                         max_epochs=hp[\"EPOCHS\"], lr_min=hp[\"LR_MIN\"])\n",
        "    stopper = EarlyStopping(patience=hp[\"PATIENCE\"], min_delta=1e-4)\n",
        "    ema   = EMA(model, decay=hp[\"EMA_DECAY\"]) if config[\"USE_EMA\"] else None\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
        "\n",
        "    # Curriculum ramp for augmentation strength\n",
        "    total_epochs  = int(hp[\"EPOCHS\"])\n",
        "    aug_ramp_frac = float(hp.get(\"AUG_RAMP_EPOCHS\", 0.30))\n",
        "    ramp_epochs   = max(1, int(aug_ramp_frac * total_epochs))\n",
        "\n",
        "    # Feature flags for late-phase controls\n",
        "    cap_late   = bool(config.get(\"AUG_CAP_LATE\", True))\n",
        "    taper_late = bool(config.get(\"TAPER_MIX_LATE\", True))\n",
        "\n",
        "    history = []\n",
        "    best_val = float(\"inf\")  # track best val_loss for reference/logging\n",
        "\n",
        "    for epoch in range(1, total_epochs + 1):\n",
        "        model.train()\n",
        "        epoch_loss_sum = 0.0\n",
        "        num_seen = 0\n",
        "\n",
        "        # ----- Build augmentation for this epoch -----\n",
        "        if config[\"USE_AUG\"]:\n",
        "            # curriculum strength in [0.2, 0.8]\n",
        "            s = 0.2 + 0.6 * min(1.0, epoch / ramp_epochs)\n",
        "            # optional cap in the final 30% to better match val distribution\n",
        "            if cap_late and epoch >= int(0.7 * total_epochs):\n",
        "                s = min(s, 0.6)\n",
        "            augment = FER_AUG_FACTORY(s)\n",
        "        else:\n",
        "            augment = None\n",
        "\n",
        "        # ----- Late-phase taper for mixing (MixUp/CutMix) -----\n",
        "        mixup_alpha  = float(hp[\"MIXUP_ALPHA\"])\n",
        "        cutmix_alpha = float(hp[\"CUTMIX_ALPHA\"])\n",
        "        use_cutmix   = bool(config[\"USE_CUTMIX\"])\n",
        "\n",
        "        if taper_late and epoch >= int(0.5 * total_epochs):\n",
        "            mixup_alpha  = max(0.1, mixup_alpha * 0.5)   # softer mixing\n",
        "            cutmix_alpha = max(0.5, cutmix_alpha * 0.5) # smaller boxes\n",
        "        if taper_late and epoch >= int(0.7 * total_epochs):\n",
        "            use_cutmix = False  # sharpen decision boundaries late\n",
        "\n",
        "        # ===================== Train loop =====================\n",
        "        for xb, yb in train_dl:\n",
        "            xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
        "\n",
        "            # Apply augmentation or deterministic normalization\n",
        "            if augment is not None:\n",
        "                # advanced policy returns tensors already normalized to [-1,1]\n",
        "                xb = torch.stack([augment(x) for x in xb])  # [-1,1]\n",
        "            else:\n",
        "                xb = ((xb / 255.0) - 0.5) * 2.0\n",
        "\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "\n",
        "            with torch.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=torch.cuda.is_available()):\n",
        "                if config[\"USE_MIXUP\"] or use_cutmix:\n",
        "                    if use_cutmix and random.random() < 0.5:\n",
        "                        xb, targets_mix, lam, _ = cutmix_data(\n",
        "                            xb, yb, alpha=cutmix_alpha, min_lam=0.3, max_lam=0.7\n",
        "                        )\n",
        "                    else:\n",
        "                        xb, targets_mix, lam, _ = mixup_data(xb, yb, alpha=mixup_alpha)\n",
        "                    logits = model(xb)\n",
        "                    loss   = mixed_criterion(criterion, logits, targets_mix, lam)\n",
        "                else:\n",
        "                    logits = model(xb)\n",
        "                    loss   = criterion(logits, yb)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            if torch.cuda.is_available():\n",
        "                scaler.unscale_(opt)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "\n",
        "            if ema is not None:\n",
        "                ema.update(model)\n",
        "\n",
        "            bs = xb.size(0)\n",
        "            epoch_loss_sum += loss.item() * bs\n",
        "            num_seen += bs\n",
        "\n",
        "        # ===================== Validation =====================\n",
        "        @torch.no_grad()\n",
        "        def _eval(loader):\n",
        "            model.eval()\n",
        "            losses, accs = [], []\n",
        "            for xb, yb in loader:\n",
        "                xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
        "                xb = ((xb / 255.0) - 0.5) * 2.0  # eval is augmentation-free\n",
        "                logits = model(xb)\n",
        "                l = criterion(logits, yb)\n",
        "                a = accuracy(logits, yb)\n",
        "                losses.append(l.item()); accs.append(a.item())\n",
        "            return float(np.mean(losses)), float(np.mean(accs))\n",
        "\n",
        "        val_loss, val_acc = _eval(valid_dl)\n",
        "\n",
        "        # Scheduler step after seeing validation\n",
        "        lr_now = sched.step()\n",
        "\n",
        "        # Epoch bookkeeping\n",
        "        train_loss = epoch_loss_sum / max(1, num_seen)\n",
        "        history.append({\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_acc\": val_acc,\n",
        "            \"lr\": lr_now\n",
        "        })\n",
        "\n",
        "        # Logging with best marker on val_loss (early stop follows this)\n",
        "        is_best = \"\"\n",
        "        if val_loss < best_val - 1e-6:\n",
        "            best_val = val_loss\n",
        "            is_best = \" *best*\"\n",
        "        print(f\"[Epoch {epoch:03d}/{total_epochs}] \"\n",
        "              f\"train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  \"\n",
        "              f\"val_acc={val_acc:.4f}  lr={lr_now:.2e}{is_best}\")\n",
        "\n",
        "        # Early stopping on validation loss\n",
        "        if stopper.step(val_loss):\n",
        "            print(\"[EarlyStopping] Patience exhausted; stopping training.\")\n",
        "            break\n",
        "\n",
        "    return history, ema\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KE1e7ExPtTP"
      },
      "source": [
        "#Cell 24 — Integration Debug: One Forward/Backward Probe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4_cgoJ2PwbQ"
      },
      "outputs": [],
      "source": [
        "# Build the model exactly as we intend to train/evaluate it.\n",
        "# Assumes HybridEffNet(num_classes=7, classifier_dropout=0.30, use_cbam=True) from Cell 21.\n",
        "\n",
        "model = HybridEffNet(num_classes=7, classifier_dropout=0.30, use_cbam=True)\n",
        "model.train()\n",
        "\n",
        "# Quick param count banner\n",
        "total_params = sum(p.numel() for p in model.parameters()) / 1e6\n",
        "print(f\"[Probe] model params ≈ {total_params:.2f}M, device={model.device}\")\n",
        "\n",
        "# One mini-batch probe (sanity check on shapes, loss, and gradients)\n",
        "xb, yb = next(iter(train_dl))\n",
        "xb, yb = xb.to(model.device), yb.to(model.device)\n",
        "\n",
        "# Deterministic normalization for the probe (no augmentation here)\n",
        "xb = ((xb / 255.0) - 0.5) * 2.0\n",
        "\n",
        "# Mixed precision probe if CUDA is available\n",
        "model.zero_grad(set_to_none=True)\n",
        "with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=torch.cuda.is_available()):\n",
        "    logits = model(xb)\n",
        "    loss   = F.cross_entropy(logits, yb)\n",
        "\n",
        "loss.backward()\n",
        "head_grad_norm = model.head.weight.grad.norm().item()\n",
        "print(f\"[Probe] logits={tuple(logits.shape)}, loss={loss.item():.4f}, grad_head_norm={head_grad_norm:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CljeZ8RPyPk"
      },
      "source": [
        "#Cell 25 — Launch Training (FER-only Path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpsSwTOYP0-d"
      },
      "outputs": [],
      "source": [
        "# Trains with the current switches and HP (keeps your dict name \"HP\").\n",
        "# Uses EMA if CONFIG[\"USE_EMA\"] is True; history and ema_obj are returned\n",
        "# from fit_with_aug() and can be reused by evaluation cells.\n",
        "\n",
        "if CONFIG[\"RUN_FER\"] and not CONFIG[\"DRY_RUN\"]:\n",
        "    print(\"[Stage3] Starting training…\")\n",
        "    history, ema_obj = fit_with_aug(model, train_dl, valid_dl, HP, CONFIG)\n",
        "else:\n",
        "    print(\"[Stage3] Skipping training due to DRY_RUN or RUN_FER=False.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eukgZdYikv1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJFgErAOP4-u"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#25B"
      ],
      "metadata": {
        "id": "z9L7jrxtoaho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#25B"
      ],
      "metadata": {
        "id": "cN7V8sAMoXwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ===== Cell 25b — Late-phase clean fine-tune (NEW) =====\n",
        "# Run AFTER your main training (Cell 25). Reload best weights and do a short cool-down:\n",
        "#  - No aug, no MixUp/CutMix\n",
        "#  - Lower LR with cosine tail\n",
        "#  - EMA with slightly higher decay\n",
        "#  - Gentler label smoothing (eps=0.05)\n",
        "\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# 1) Reload best checkpoint you just saved\n",
        "ckpt = torch.load(CONFIG[\"SAVE_BEST_PATH\"], map_location=\"cpu\", weights_only=False)\n",
        "model.load_state_dict(ckpt[\"model_state\"])\n",
        "model.to(model.device).train()\n",
        "\n",
        "# 2) Freeze heavy regularisation during the tail\n",
        "CONFIG.update({\"USE_AUG\": False, \"USE_MIXUP\": False, \"USE_CUTMIX\": False})\n",
        "\n",
        "# 3) Tail hyperparameters\n",
        "HP_TAIL = dict(HP, EPOCHS=8, LR=3e-5, LR_MIN=1e-6, PATIENCE=max(12, HP.get(\"PATIENCE\", 8)))\n",
        "\n",
        "# 4) Light criterion for the tail\n",
        "tail_criterion = LabelSmoothingCE(eps=0.05)\n",
        "\n",
        "# 5) Optimizer / scheduler / EMA for tail\n",
        "optimizer = make_adamw(model.parameters(), lr=HP_TAIL[\"LR\"], wd=HP_TAIL[\"WD\"])\n",
        "sched     = WarmupCosine(optimizer, warmup_epochs=1, max_epochs=HP_TAIL[\"EPOCHS\"], lr_min=HP_TAIL[\"LR_MIN\"])\n",
        "ema_tail  = EMA(model, decay=0.9995)\n",
        "\n",
        "history_tail = []\n",
        "for epoch in range(1, HP_TAIL[\"EPOCHS\"] + 1):\n",
        "    model.train()\n",
        "    for xb, yb in train_dl:\n",
        "        xb, yb = xb.to(model.device, non_blocking=True), yb.to(model.device, non_blocking=True)\n",
        "        xb = ((xb / 255.0) - 0.5) * 2.0  # no aug in tail\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=torch.cuda.is_available()):\n",
        "            logits = model(xb)\n",
        "            loss   = tail_criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "        optimizer.step()\n",
        "        ema_tail.update(model)\n",
        "    # one cosine step per epoch\n",
        "    sched.step()\n",
        "\n",
        "    # quick validation probe with EMA weights applied\n",
        "    ema_tail.apply_shadow(model)\n",
        "    v_loss, v_acc = model.evaluate_loader(valid_dl, tail_criterion)\n",
        "    ema_tail.restore(model)\n",
        "    history_tail.append({\"epoch\": epoch, \"val_loss\": v_loss, \"val_acc\": v_acc})\n",
        "    print(f\"[Tail {epoch:02d}/{HP_TAIL['EPOCHS']}] val_acc={v_acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "_nNeGlIWn25N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iYJlISHaokxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Cell 26a — Exam header + helpers (NEW) =====\n",
        "# Banner + small utilities reused by later cells.\n",
        "\n",
        "import math, random, numpy as np, torch, torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fill these for your report\n",
        "STUDENT_NAME = \"ABC, XYZ\"\n",
        "STUDENT_ID   = \"a123456, a654321\"\n",
        "COMP_NAME    = \"Facial Expression Recognition/Classification\"\n",
        "\n",
        "print(\"######################################################################\")\n",
        "print(\"### Subject: Computer Vision\")\n",
        "print(\"### Year: 2025\")\n",
        "print(f\"### Student Name: {STUDENT_NAME}\")\n",
        "print(f\"### Student ID:   {STUDENT_ID}\")\n",
        "print(f\"### Competition:  {COMP_NAME}\")\n",
        "print(\"######################################################################\\n\")\n",
        "\n",
        "IDX2EMO = {0:'Angry',1:'Disgust',2:'Fear',3:'Happy',4:'Sad',5:'Surprise',6:'Neutral'}\n",
        "\n",
        "def _dev(m):\n",
        "    return next(m.parameters()).device\n",
        "\n",
        "def _denorm_img(x):\n",
        "    # for tensors normalized with mean=0.5,std=0.5\n",
        "    if x.dtype.is_floating_point:\n",
        "        return (x * 0.5 + 0.5).clamp(0,1)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "9zvOMmLYpbgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Cell 26b — Training curves: main + tail (NEW) =====\n",
        "# Uses `history` from Cell 25 and `history_tail` from 25b (if present).\n",
        "\n",
        "def _extract_series(hist, key):\n",
        "    if not isinstance(hist, (list, tuple)):\n",
        "        return []\n",
        "    out = []\n",
        "    for h in hist:\n",
        "        if isinstance(h, dict) and key in h:\n",
        "            v = h[key]\n",
        "            if isinstance(v, (float, int)): out.append(v)\n",
        "    return out\n",
        "\n",
        "main_val_acc  = _extract_series(globals().get(\"history\", []), \"val_acc\")\n",
        "main_val_loss = _extract_series(globals().get(\"history\", []), \"val_loss\")\n",
        "tail_val_acc  = _extract_series(globals().get(\"history_tail\", []), \"val_acc\")\n",
        "tail_val_loss = _extract_series(globals().get(\"history_tail\", []), \"val_loss\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "axes[0].set_title(\"Validation Accuracy vs Epoch\")\n",
        "axes[0].set_xlabel(\"epoch\"); axes[0].set_ylabel(\"val_acc\")\n",
        "if main_val_acc: axes[0].plot(main_val_acc, marker='x', label=\"main\")\n",
        "if tail_val_acc:\n",
        "    xs = range(len(main_val_acc), len(main_val_acc)+len(tail_val_acc))\n",
        "    axes[0].plot(xs, tail_val_acc, marker='o', label=\"tail\")\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].set_title(\"Loss vs Epoch\")\n",
        "axes[1].set_xlabel(\"epoch\"); axes[1].set_ylabel(\"loss\")\n",
        "if main_val_loss: axes[1].plot(main_val_loss, marker='x', label=\"main\")\n",
        "if tail_val_loss:\n",
        "    xs = range(len(main_val_loss), len(main_val_loss)+len(tail_val_loss))\n",
        "    axes[1].plot(xs, tail_val_loss, marker='o', label=\"tail\")\n",
        "axes[1].legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mY451sSbpcUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SK7P4z_tpdt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Cell 26c — Random image preview with predictions (NEW) =====\n",
        "# Shows an n×n grid from TEST (falls back to VALID) with model predictions.\n",
        "\n",
        "@torch.no_grad()\n",
        "def preview_predictions(model, dataset, n=16, use_ema=True, ema_primary=\"ema_obj\"):\n",
        "    device = _dev(model)\n",
        "    ema_obj = globals().get(ema_primary, None)\n",
        "    if use_ema and ema_obj is not None:\n",
        "        ema_obj.apply_shadow(model)\n",
        "    model.eval()\n",
        "\n",
        "    idxs = random.sample(range(len(dataset)), k=min(n, len(dataset)))\n",
        "    imgs, gts, preds = [], [], []\n",
        "    for i in idxs:\n",
        "        x, y = dataset[i]                    # x: (1,48,48) normalized\n",
        "        x_in  = x.unsqueeze(0).to(device)    # (1,1,48,48)\n",
        "        logits = model(x_in)\n",
        "        p = int(logits.argmax(1).item())\n",
        "        imgs.append(_denorm_img(x).squeeze(0).cpu().numpy())\n",
        "        gts.append(int(y)); preds.append(p)\n",
        "\n",
        "    if use_ema and ema_obj is not None:\n",
        "        ema_obj.restore(model)\n",
        "\n",
        "    cols = int(math.sqrt(len(imgs))) or 1\n",
        "    rows = math.ceil(len(imgs)/cols)\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(1.8*cols, 1.8*rows))\n",
        "    axes = np.array(axes).reshape(rows, cols)\n",
        "    for k, ax in enumerate(axes.flat):\n",
        "        ax.axis(\"off\")\n",
        "        if k < len(imgs):\n",
        "            ax.imshow(imgs[k], cmap='gray', interpolation='nearest')\n",
        "            ok = (gts[k] == preds[k])\n",
        "            ax.set_title(f\"T:{IDX2EMO[gts[k]]}\\nP:{IDX2EMO[preds[k]]}\" + (\"\" if ok else \" *\"),\n",
        "                         fontsize=8)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "_preview_ds = globals().get(\"test_ds\", None) or globals().get(\"valid_ds\", None)\n",
        "if _preview_ds is not None:\n",
        "    preview_predictions(model, _preview_ds, n=16, use_ema=True, ema_primary=\"ema_obj\")\n"
      ],
      "metadata": {
        "id": "Ob-imLrNpfSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Cell 26d — Confusion matrix + per-class accuracy on TEST (NEW) =====\n",
        "import itertools\n",
        "@torch.no_grad()\n",
        "def confusion_matrix_and_report(model, loader, num_classes=7, use_ema=True, ema_primary=\"ema_obj\"):\n",
        "    device = _dev(model)\n",
        "    ema_obj = globals().get(ema_primary, None)\n",
        "    if use_ema and ema_obj is not None:\n",
        "        ema_obj.apply_shadow(model)\n",
        "\n",
        "    model.eval()\n",
        "    cm = torch.zeros(num_classes, num_classes, dtype=torch.int64)\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        xb = ((xb/255.0)-0.5)*2.0 if xb.dtype.is_floating_point and xb.max()>1.5 else xb\n",
        "        logits = model(xb)\n",
        "        preds = logits.argmax(1)\n",
        "        for t, p in zip(yb.view(-1), preds.view(-1)):\n",
        "            cm[t.long(), p.long()] += 1\n",
        "\n",
        "    if use_ema and ema_obj is not None:\n",
        "        ema_obj.restore(model)\n",
        "\n",
        "    cm_np = cm.cpu().numpy()\n",
        "    denom = cm.sum(dim=1).clamp(min=1).cpu().numpy()\n",
        "    per_class_acc = cm.diagonal().cpu().numpy() / denom\n",
        "    return cm_np, per_class_acc\n",
        "\n",
        "_test_loader = globals().get(\"test_dl\", None) or globals().get(\"valid_dl\", None)\n",
        "if _test_loader is not None:\n",
        "    cm, pc_acc = confusion_matrix_and_report(model, _test_loader, num_classes=7, use_ema=True, ema_primary=\"ema_obj\")\n",
        "    fig = plt.figure(figsize=(6,5))\n",
        "    plt.imshow(cm)\n",
        "    plt.title(\"Confusion Matrix (rows=true, cols=pred)\")\n",
        "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
        "    plt.xticks(range(7), [IDX2EMO[i] for i in range(7)], rotation=45, ha='right')\n",
        "    plt.yticks(range(7), [IDX2EMO[i] for i in range(7)])\n",
        "    for i, j in itertools.product(range(7), range(7)):\n",
        "        if cm[i, j] > 0:\n",
        "            plt.text(j, i, int(cm[i, j]), ha=\"center\", va=\"center\", fontsize=7)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "    print(\"Per-class accuracy:\")\n",
        "    for i, a in enumerate(pc_acc):\n",
        "        print(f\"  {IDX2EMO[i]:>8s}: {a*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "wI6Co5UZpf9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Cell 26e — Quick accuracy snapshot (NEW) =====\n",
        "# If you have not run the replaced Cell 27 yet, this gives a fast val/test accuracy (no TTA).\n",
        "@torch.no_grad()\n",
        "def _quick_eval(model, loader, use_ema=True, ema_primary=\"ema_obj\"):\n",
        "    device = _dev(model)\n",
        "    ema_obj = globals().get(ema_primary, None)\n",
        "    if use_ema and ema_obj is not None:\n",
        "        ema_obj.apply_shadow(model)\n",
        "    model.eval(); total, correct, losses = 0, 0, []\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        xb = ((xb/255.0)-0.5)*2.0 if xb.dtype.is_floating_point and xb.max()>1.5 else xb\n",
        "        logits = model(xb)\n",
        "        loss = F.cross_entropy(logits, yb)\n",
        "        pred = logits.argmax(1)\n",
        "        correct += (pred==yb).sum().item(); total += yb.size(0); losses.append(loss)\n",
        "    if use_ema and ema_obj is not None:\n",
        "        ema_obj.restore(model)\n",
        "    return float(torch.stack(losses).mean().item()), correct/total\n",
        "\n",
        "if \"val_acc_base\" not in globals() and globals().get(\"valid_dl\", None) is not None:\n",
        "    _, val_acc_base = _quick_eval(model, valid_dl, use_ema=True)\n",
        "if \"test_acc_base\" not in globals() and globals().get(\"test_dl\", None) is not None:\n",
        "    _, test_acc_base = _quick_eval(model, test_dl, use_ema=True)\n",
        "\n",
        "print(\"Snapshot Accuracies (no TTA):\")\n",
        "print(f\"  Val  : {val_acc_base*100:.2f}%\"  if 'val_acc_base'  in globals() and val_acc_base  is not None else \"  Val  : N/A\")\n",
        "print(f\"  Test : {test_acc_base*100:.2f}%\" if 'test_acc_base' in globals() and test_acc_base is not None else \"  Test : N/A\")\n"
      ],
      "metadata": {
        "id": "4eoMy9SOpirM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Cell 27 — Run Evaluation (Val clean; Test optional TTA) [REPLACE] =====\n",
        "@torch.no_grad()\n",
        "def eval_loader(model, loader):\n",
        "    model.eval()\n",
        "    device = model.device\n",
        "    total, correct = 0, 0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        xb = ((xb/255.0)-0.5)*2.0\n",
        "        logits = model(xb)\n",
        "        pred = logits.argmax(1)\n",
        "        correct += (pred==yb).sum().item(); total += yb.size(0)\n",
        "    return correct/total\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_loader_tta(model, loader, n=6):\n",
        "    model.eval()\n",
        "    device = model.device\n",
        "    total, correct = 0, 0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        xb = ((xb/255.0)-0.5)*2.0\n",
        "        logits = 0\n",
        "        for t in range(n):\n",
        "            xb_t = xb.flip(-1) if (t % 2 == 1) else xb\n",
        "            logits = logits + model(xb_t)\n",
        "        logits = logits / n\n",
        "        pred = logits.argmax(1)\n",
        "        correct += (pred==yb).sum().item(); total += yb.size(0)\n",
        "    return correct/total\n",
        "\n",
        "# 1) Validation (no TTA, always clean)\n",
        "val_acc_base = eval_loader(model, valid_dl)\n",
        "val_acc_ema  = None\n",
        "val_acc_tta  = None\n",
        "if 'ema_obj' in globals() and ema_obj is not None:\n",
        "    ema_obj.apply_shadow(model)\n",
        "    val_acc_ema = eval_loader(model, valid_dl)\n",
        "    ema_obj.restore(model)\n",
        "\n",
        "# 2) Test (allow light TTA if desired)\n",
        "test_acc_base = eval_loader(model, test_dl)\n",
        "test_acc_ema  = None\n",
        "test_acc_tta  = None\n",
        "if 'ema_obj' in globals() and ema_obj is not None:\n",
        "    ema_obj.apply_shadow(model)\n",
        "    test_acc_ema = eval_loader(model, test_dl)\n",
        "    # enable TTA here only if you want it; Val stays clean\n",
        "    CONFIG[\"USE_TTA\"] = True\n",
        "    if CONFIG[\"USE_TTA\"]:\n",
        "        test_acc_tta = eval_loader_tta(model, test_dl, n=6)\n",
        "    ema_obj.restore(model)\n",
        "\n",
        "print(f\"[Eval] val_base={val_acc_base:.4f} val_ema={val_acc_ema}\")\n",
        "print(f\"[Eval] test_base={test_acc_base:.4f} test_ema={test_acc_ema} test_tta={test_acc_tta}\")\n"
      ],
      "metadata": {
        "id": "FIJuDPT-p2VL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Cell 28 — FLOPs (fvcore) install + measure [REPLACE] =====\n",
        "import sys, subprocess, importlib\n",
        "def _pip_install(pkg):\n",
        "    try:\n",
        "        importlib.import_module(pkg)\n",
        "    except Exception:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
        "\n",
        "try:\n",
        "    from fvcore.nn import FlopCountAnalysis\n",
        "except Exception:\n",
        "    _pip_install(\"fvcore\")\n",
        "    from fvcore.nn import FlopCountAnalysis\n",
        "\n",
        "model.eval()\n",
        "IMG_SIZE = int(CONFIG[\"IMG_SIZE\"])\n",
        "dummy = torch.randn(1, 1, IMG_SIZE, IMG_SIZE, device=model.device)\n",
        "dummy = ((dummy/255.0)-0.5)*2.0\n",
        "flops_total = FlopCountAnalysis(model, dummy).total()\n",
        "MFLOPs = float(flops_total) / 1e6\n",
        "print(f\"[FLOPs] {MFLOPs:.2f} MFLOPs @ {IMG_SIZE}x{IMG_SIZE}\")\n"
      ],
      "metadata": {
        "id": "n0IVhihBp3dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Cell 29 — Efficiency report (% per GFLOP) [REPLACE] =====\n",
        "def _best_accuracy(*vals):\n",
        "    vals = [v for v in vals if isinstance(v, (float, int))]\n",
        "    return max(vals) if vals else None\n",
        "\n",
        "acc_best_val  = _best_accuracy(val_acc_base, val_acc_ema, val_acc_tta)\n",
        "acc_best_test = _best_accuracy(test_acc_base,\n",
        "                               ('test_acc_ema' in globals()) and test_acc_ema or None,\n",
        "                               ('test_acc_tta' in globals()) and test_acc_tta or None)\n",
        "\n",
        "def efficiency_pct_per_gflop(acc_frac: float, mflops: float) -> float:\n",
        "    assert mflops > 0, \"MFLOPs must be positive\"\n",
        "    return (acc_frac * 100.0) / (mflops / 1000.0)\n",
        "\n",
        "eff_val  = efficiency_pct_per_gflop(acc_best_val,  MFLOPs) if (acc_best_val  is not None) else None\n",
        "eff_test = efficiency_pct_per_gflop(acc_best_test, MFLOPs) if (acc_best_test is not None) else None\n",
        "\n",
        "print(\"[Efficiency]\")\n",
        "print(f\"  - val_best_acc   = {acc_best_val:.4f}\"  if acc_best_val  is not None else \"  - val_best_acc   = N/A\")\n",
        "print(f\"  - test_best_acc  = {acc_best_test:.4f}\" if acc_best_test is not None else \"  - test_best_acc  = N/A\")\n",
        "print(f\"  - MFLOPs         = {MFLOPs:.2f}\")\n",
        "print(f\"  - val %/GFLOP    = {eff_val:.2f}\"  if eff_val  is not None else \"  - val %/GFLOP    = N/A\")\n",
        "print(f\"  - test %/GFLOP   = {eff_test:.2f}\" if eff_test is not None else \"  - test %/GFLOP   = N/A\")\n"
      ],
      "metadata": {
        "id": "EASKYr5Sp5Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Cell 31 — Robust checkpoint reload (PyTorch 2.6‑safe) [REPLACE] =====\n",
        "from pathlib import PosixPath\n",
        "from torch.serialization import add_safe_globals\n",
        "\n",
        "add_safe_globals([PosixPath])  # allowlist PosixPath under weights_only=True\n",
        "\n",
        "try:\n",
        "    ckpt_safe = torch.load(CONFIG[\"SAVE_BEST_PATH\"], map_location=\"cpu\")  # PT 2.6 default: weights_only=True\n",
        "except Exception as e:\n",
        "    print(f\"[Reload][WARN] Safe-load failed ({e}); retrying with weights_only=False (trusted local file).\")\n",
        "    ckpt_safe = torch.load(CONFIG[\"SAVE_BEST_PATH\"], map_location=\"cpu\", weights_only=False)\n",
        "\n",
        "assert \"model_state\" in ckpt_safe, \"Checkpoint missing 'model_state'\"\n",
        "print(\"[Reload] Checkpoint structure OK.\")\n"
      ],
      "metadata": {
        "id": "z8xVaCGUp6hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Cell 31b — Final run summary (NEW) =====\n",
        "summary = {\n",
        "    \"val_base\":  float(val_acc_base),\n",
        "    \"val_ema\":   float(val_acc_ema) if val_acc_ema is not None else None,\n",
        "    \"val_tta\":   float(val_acc_tta) if val_acc_tta is not None else None,\n",
        "    \"test_base\": float(test_acc_base),\n",
        "    \"test_ema\":  float(test_acc_ema) if 'test_acc_ema' in globals() and test_acc_ema is not None else None,\n",
        "    \"test_tta\":  float(test_acc_tta) if 'test_acc_tta' in globals() and test_acc_tta is not None else None,\n",
        "    \"MFLOPs\":    float(MFLOPs),\n",
        "    \"val_%/GFLOP\":  float((val_acc_base if val_acc_ema is None else max(val_acc_base, val_acc_ema)) * 1000.0 / MFLOPs),\n",
        "    \"test_%/GFLOP\": float((max(x for x in [test_acc_base, ('test_acc_ema' in globals()) and test_acc_ema or None, ('test_acc_tta' in globals()) and test_acc_tta or None] if isinstance(x,(float,int))) * 1000.0 / MFLOPs)),\n",
        "    \"ckpt_path\":  str(CONFIG[\"SAVE_BEST_PATH\"]),\n",
        "}\n",
        "print(\"\\n===== RUN SUMMARY =====\")\n",
        "for k, v in summary.items():\n",
        "    print(f\"{k:>13s}: {v}\")\n",
        "print(\"=======================\\n\")\n"
      ],
      "metadata": {
        "id": "8bCWzpAop8qq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}